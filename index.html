<!DOCTYPE html>
<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">



<title>Zhuoyuan Li</title>
<meta content="Rui Zhao" name="Rui Zhao">
<link href="./zhuoyuan_files/style.css" rel="stylesheet" type="text/css">
<script src="./zhuoyuan_files/jquery-1.11.1.min.js" type="text/javascript"></script>  
</head>

<body>
  <div class="menu"> <a href="https://ZhuoyuanLi1997.github.io/index.html">Home</a> 
  <a href="https://ZhuoyuanLi1997.github.io/index.html#news">News</a> 
  <a href="https://ZhuoyuanLi1997.github.io/index.html#bio">Bio</a> 
  <a href="https://ZhuoyuanLi1997.github.io/index.html#education">Education</a>
  <a href="https://ZhuoyuanLi1997.github.io/index.html#publications">Publications</a>
  <a href="https://ZhuoyuanLi1997.github.io/index.html#services">Services</a>   
  </div>
  <div class="container">
    <table border="0" class="profile">
      <tbody><tr>
        <td><img src="./zhuoyuan_files/zhuoyuanli.JPG" width="160" height=""></td>
        <td style="width: 40px">&nbsp;</td>
        <td valign="top" width="800">
          <span class="name">Zhuoyuan Li (李卓元)</span>
          <p class="information"><br>
          Ph.D. Candidate,<br>
          <a href="https://ustc-ivclab.github.io/">intelligent Visual Data Coding Laboratory (iVC lab),</a> <br>
          <a href="https://en.sist.ustc.edu.cn/main.htm">Dept. EEIS, School of Information Science and Technology,</a><br>
          <a href="http://en.ustc.edu.cn/">University of Science and Technology of China (USTC)</a>.</p>

          <p class="information">No. 100 Fuxing Road, <br>
          Hefei, Anhui Province, China<br>
          Room 603 & 609, XinZhi Building, University of Science and Technology of China.
          <p class="information"><strong>E-mail</strong>: <span class="unselectable">zhuoyuanli</span>@mail.ustc.edu.cn</span> </p>
          <p class="information"><strong>WeChat</strong>: <span class="unselectable">ustc_lizhuoyuan </p>  
          <a href="https://scholar.google.com/citations?user=PiyMuF4AAAAJ&hl=zh-CN">Google Scholar</a> &nbsp;&nbsp;&nbsp;&nbsp;  
          <a href="https://www.linkedin.com/in/zhuoyuan-li-a03aa6276/">Linkedin</a> &nbsp;&nbsp;&nbsp;&nbsp;
          <a href="https://github.com/ZhuoyuanLi1997?tab=repositories">Github</a> &nbsp;&nbsp;&nbsp;&nbsp;
          <a href="https://dblp.org/pid/81/2220-1.html">DBLP</a> &nbsp;&nbsp;&nbsp;&nbsp;
          <a href="https://orcid.org/0009-0003-7370-4068">ORCID</a> &nbsp;&nbsp;&nbsp;&nbsp;
          <a href="https://openreview.net/profile?id=~Zhuoyuan_Li2">OpenReview</a> &nbsp;&nbsp;&nbsp;&nbsp;
        </td>
      </tr>
    </tbody></table>

    <a id="bio" class="anchor"></a>
    <span class="section">Brief Bio</span>
    <table border="0" class="bio" width="95%">
    <tr>
    <td width="80%">
      I am Zhuoyuan Li (Milk). I received the B.E. degree in Communication Engineering from the Southwest Jiaotong University, Sichuan, China, in 2020.
      I am currently pursuing the Ph.D. degree in Information and Communication Engineering with University of Science and Technology of China (USTC), Hefei, China, supervised by <a href="https://scholar.google.com/citations?user=5bInRDEAAAAJ&hl=zh-CN&oi=ao">Prof. Feng Wu</a> and <a href="https://faculty.ustc.edu.cn/dongeliu/">Prof. Dong Liu</a>. 
      I also worked closely with <a href="https://faculty.ustc.edu.cn/lil1/en">Prof. Li Li</a> and many good friends from <a href="https://ustc-ivclab.github.io/">USTC-iVC</a> && <a href="https://vidar-ustc.github.io/">VIDAR</a> lab. My research interests include areas of <strong> Traditional Image/Video Coding</strong>, learned image/video compression
      and image/video processing, particularly for topics related to <strong>Inter Prediction</strong>, Intra Prediction, In-Loop Filtering, and Deep Learning-based Coding Tools in traditional codecs (H.266/VVC, AV2, H.265/HEVC).
    </td>
    </tr>
  </table>

    <a id="news" class="anchor"></a>
    <span class="section">News</span>
    <table border="0" class="news">
    <tr>
      <td>
        <p><strong>[2026.02]</strong> Invited as the reviewer for ACM MM 2026. </p>
        <p><strong>[2026.01]</strong> Invited as the reviewer for ECCV 2026. </p>
      </td>
    </tr>
  </table>

    <a id="education" class="education"></a><span class="section">Education</span>
    <p class="education">
    <b>University of Science and Technology of China (USTC)</b>. <br>
    2020 - 2025, &nbsp;&nbsp;&nbsp; Ph.D., &nbsp; Information and Communication Engineering.       
    </p>
    <p class="education">
      <b>Southwest Jiaotong University (SWJTU)</b>. <br>
      2016 - 2020, &nbsp;&nbsp;&nbsp;   B.Eng., Communication Engineering.       
    </p>
      
    <a id="publications" class="anchor"></a><span class="section">Selected Publications</a> </span>
    <table border="0" width="95%" class="paper" style="border-collapse:separate; border-spacing:10px;">
      <tbody>

      <tr>
        <td style="line-height: 1.5;">
          <img src="./images/pic/SAIP-crop.png" width="200" height="100">
        </td>
        <td>
          <papertitle style="line-height: 1.5;"> 
          <a href="https://ieeexplore.ieee.org/document/10623319"> 
          Object Segmentation-Assisted Inter Prediction for Versatile Video Coding</a></papertitle> <br>
          <strong>Zhuoyuan Li</strong>, Zikun Yuan, Li Li, Dong Liu*, Xiaohu Tang, and Feng Wu <br>
          <em> IEEE Transactions on Broadcasting </em> (TBC), 2024 <br>
          <span style="color: rgba(89, 0, 255, 0.753);">Related Codec: 
          <a href="https://ieeexplore.ieee.org/abstract/document/9503377">H.266/VVC</a>, 
          Related Module: 
          <a href="https://ieeexplore.ieee.org/abstract/document/9502124">Inter Prediction</a></span><br>
          [<a href="./files/SAIP/SAIP-TBC.pdf">PDF</a>] 
          [<a href="https://ieeexplore.ieee.org/document/10623319">DOI</a>]
          [<a href="https://arxiv.org/abs/2403.11694">arXiv</a>]
        </td>
      </tr>

      <tr>
        <td style="line-height: 1.5;">
          <img src="./images/pic/ustc-td-crop.png" width="200" height="130">
        </td>
        <td>
          <papertitle style="line-height: 1.5;"> 
          <a href="https://esakak.github.io/USTC-TD/"> USTC-TD: A Test Dataset and Benchmark for Image and Video Coding in 2020s</a></papertitle> <br>
          <strong>Zhuoyuan Li</strong>, Junqi Liao (Co-first), Chuanbo Tang, Haotian Zhang, Yuqi Li, Yifan Bian, Xihua Sheng, Xinmin Feng, Yao Li, Changsheng Gao, Li Li, Dong Liu*, and Feng Wu* <br>
          <em> IEEE Transactions on Multimedia</em> (TMM), 2025 <br>
          <span style="color: rgba(89, 0, 255, 0.753);">Related Traditional Codec: 
          <a href="https://ieeexplore.ieee.org/abstract/document/9503377">H.266/VVC</a>, 
          <a href="https://ieeexplore.ieee.org/abstract/document/6316136">H.265/HEVC</a>, 
          <a href="https://bellard.org/bpg/">BPG</a></span><br>
          <span style="color: rgba(89, 0, 255, 0.753);">Related End-to-End Image Codec: 
          <a href="https://arxiv.org/abs/1802.01436">Factorized Model</a>,
          <a href="https://arxiv.org/abs/1802.01436">Hyperprior Model</a>, 
          <a href="https://proceedings.neurips.cc/paper/2018/hash/53edebc543333dfbf7c5933af792c9c4-Abstract.html">Autoregressive Model</a>, 
          <a href="https://openaccess.thecvf.com/content_CVPR_2020/html/Cheng_Learned_Image_Compression_With_Discretized_Gaussian_Mixture_Likelihoods_and_Attention_CVPR_2020_paper.html">Cheng2020</a>, 
          <a href="https://ieeexplore.ieee.org/abstract/document/9204799">iWave++</a>,
          <a href="https://openaccess.thecvf.com/content/CVPR2022/html/He_ELIC_Efficient_Learned_Image_Compression_With_Unevenly_Grouped_Space-Channel_Contextual_CVPR_2022_paper.html">ELIC</a>, 
          <a href="https://dl.acm.org/doi/abs/10.1145/3581783.3611694">MLIC++</a></span><br>
          <span style="color: rgba(89, 0, 255, 0.753);">Related End-to-End Video Codec: 
          <a href="https://ieeexplore.ieee.org/abstract/document/9072487">DVC_Pro</a>, 
          <a href="https://proceedings.neurips.cc/paper_files/paper/2021/hash/96b250a90d3cf0868c83f8c965142d2a-Abstract.html">DCVC</a>, 
          <a href="https://link.springer.com/chapter/10.1007/978-3-031-19787-1_12">CANF-VC</a>, 
          <a href="https://ieeexplore.ieee.org/abstract/document/9941493">TCM-VC</a>, 
          <a href="https://dl.acm.org/doi/abs/10.1145/3503161.3547845">DCVC-HEM</a>, 
          <a href="https://ojs.aaai.org/index.php/AAAI/article/view/28317">OOFE</a>, 
          <a href="https://ieeexplore.ieee.org/abstract/document/10411051">VNVC</a>, 
          <a href="https://ieeexplore.ieee.org/abstract/document/10416688">SDD</a>, 
          <a href="https://openaccess.thecvf.com/content/CVPR2023/html/Li_Neural_Video_Compression_With_Diverse_Contexts_CVPR_2023_paper.html">DCVC-DC</a>, 
          <a href="https://openaccess.thecvf.com/content/CVPR2024/html/Li_Neural_Video_Compression_with_Feature_Modulation_CVPR_2024_paper.html">DCVC-FM</a></span><br>
          <span style="color: rgba(89, 0, 255, 0.753);">Related INR-based Video Codec: 
          <a href="https://proceedings.neurips.cc/paper/2021/hash/b44182379bf9fae976e6ae5996e13cd8-Abstract.html">NeRV</a>,
          <a href="https://openaccess.thecvf.com/content/CVPR2023/html/Chen_HNeRV_A_Hybrid_Neural_Representation_for_Videos_CVPR_2023_paper.html">HNerV</a>,
          <a href="https://proceedings.neurips.cc/paper_files/paper/2023/hash/e5dc475c370ff42f2f96dddf8191a40c-Abstract-Conference.html">HiNerV</a>,
          <a href="https://arxiv.org/abs/2409.07414">NVRC</span><br>
          [<a href="./files/USTC-TD/USTC-TD.pdf">PDF</a>] 
          [<a href="https://ieeexplore.ieee.org/abstract/document/11155177/">DOI</a>] 
          [<a href="./files/USTC-TD/sup.pdf">Supplementary</a>]
          [<a href="https://arxiv.org/abs/2409.08481">arXiv</a>]
          [<a href="https://esakak.github.io/USTC-TD/">Project Page</a>]
          [<a href="https://github.com/EsakaK/USTC-TD">Data</a>]
          [<a href="https://github.com/EsakaK/USTC-TD/tree/main/code">Code</a>]
        </td>
      </tr>

      <tr>
        <td style="line-height: 1.5;">
          <img src="./images/pic/LUT-ILF++-crop.png" width="200" height="100">
        </td>
        <td>
          <papertitle style="line-height: 1.5;"><a href="https://arxiv.org/abs/2509.09494">
          In-Loop Filtering Using Learned Look-Up Tables for Video Coding </a></papertitle> <br>
          <strong>Zhuoyuan Li</strong>, Jiacheng Li, Yao Li, Jialin Li, Li Li, Dong Liu*, and Feng Wu<br>
          <em> Arxiv Preprint</em>, 2025<br>
          <span style="color: rgba(89, 0, 255, 0.753);">Related Codec: 
          <a href="https://ieeexplore.ieee.org/abstract/document/9503377">H.266/VVC</a>, 
          Related Module: 
          <a href="https://ieeexplore.ieee.org/abstract/document/9399506">In-Loop Filtering</a></span><br>
          [<a href="./files/LUT-ILF++/LUT-ILF++.pdf">PDF</a>]
          [<a href="https://arxiv.org/abs/2509.09494">arXiv</a>]
        </td>
      </tr>

      <tr>
        <td style="line-height: 1.5;">
          <img src="./images/pic/UAMM-crop.png" width="200" height="45">
        </td>
        <td>
          <papertitle style="line-height: 1.5;"><a href="https://ieeexplore.ieee.org/abstract/document/10849917">
          Uniformly Accelerated Motion Model for Inter Prediction</a></papertitle> <br>
          <strong>Zhuoyuan Li</strong>, Yao Li, Chuanbo Tang, Li Li, Dong Liu, and Feng Wu*<br>
          <em> IEEE International Conference on Visual Communications and Image Processing</em> (VCIP), Poster, 2024<br>
          <span style="color: rgba(89, 0, 255, 0.753);">Related Codec: 
          <a href="https://ieeexplore.ieee.org/abstract/document/9503377">H.266/VVC</a>, 
          Related Module: 
          <a href="https://ieeexplore.ieee.org/abstract/document/9502124">Inter Prediction</a></span><br>
          [<a href="./files/UAMM/20241008_UAMM_vcip2024_camera_v2.pdf">PDF</a>] 
          [<a href="https://ieeexplore.ieee.org/abstract/document/10849917">DOI</a>] 
          [<a href="https://arxiv.org/abs/2407.11541v2">arXiv</a>]
          [<a href="./files/UAMM/20241008_UAMM_vcip2024_poster.pdf">VCIP2024 Poster</a>]
        </td>
      </tr>

      <tr>
        <td style="line-height: 1.5;">
          <img src="./images/pic/LUT-ILF-crop.png" width="200" height="90">
        </td>
        <td>
          <papertitle style="line-height: 1.5;"><a href="https://ieeexplore.ieee.org/abstract/document/10849824">
          In-Loop Filtering via Trained Look-Up Tables</a></papertitle> <br>
          <strong>Zhuoyuan Li</strong>, Jiacheng Li, Yao Li, Li Li, Dong Liu*, and Feng Wu<br>
          <em> IEEE International Conference on Visual Communications and Image Processing</em> (VCIP), Oral, 2024<br>
          <span style="color: rgba(89, 0, 255, 0.753);">Related Codec: 
          <a href="https://ieeexplore.ieee.org/abstract/document/9503377">H.266/VVC</a>, 
          Related Module: 
          <a href="https://ieeexplore.ieee.org/abstract/document/9399506">In-Loop Filtering</a></span><br>
          [<a href="./files/LUT-ILF/20241008_LUT-ILF_vcip2024_camera_v2.pdf">PDF</a>]
          [<a href="https://ieeexplore.ieee.org/abstract/document/10849824">DOI</a>] 
          [<a href="https://arxiv.org/abs/2407.10926v2">arXiv</a>]
          [<a href="./files/LUT-ILF/20241201_LUT-ILF_oral_presentation.pdf">VCIP2024 Presentation</a>]
        </td>
      </tr>

      <tr>
        <td style="line-height: 1.5;">
          <img src="./images/pic/IPC.png" width="200" height="80">
        </td>
        <td>
          <papertitle style="line-height: 1;"><a href="https://ieeexplore.ieee.org/document/10972021">
          Frequency Domain Intra Pattern Copy for JPEG XS Screen Content Coding</a></papertitle> <br>
          Yao Li, <strong>Zhuoyuan Li</strong>, Dong Liu, and Li Li*<br>
          <em> IEEE Transactions on Circuits and Systems for Video Technology </em> (TCSVT), 2025<br>
          <span style="color: rgba(89, 0, 255, 0.753);">Related Codec: 
          <a href="https://ieeexplore.ieee.org/abstract/document/9443088">JPEG XS</a>, 
          Related Module: <a href="https://ieeexplore.ieee.org/abstract/document/7547947">Intra Prediction</span><br>
          [<a href="./files/F-IPC/F-IPC.pdf">PDF</a>] 
          [<a href="https://ieeexplore.ieee.org/document/10972021">DOI</a>] 
        </td>
      </tr>

      <tr>
        <td style="line-height: 1.5;">
          <img src="./images/pic/PMPI.png" width="200" height="100">
        </td>
        <td>
          <papertitle style="line-height: 1;"><a href="https://ieeexplore.ieee.org/abstract/document/11248955">
          Partition Map-Based Fast Block Partitioning for VVC Inter Coding</a></papertitle> <br>
          Xinmin Feng, <strong>Zhuoyuan Li</strong>, Li Li, Dong Liu*, and Feng Wu<br>
          <em>IEEE Transactions on Multimedia</em> (TMM), 2025 <br>
          <span style="color: rgba(89, 0, 255, 0.753);">Related Codec: 
          <a href="https://ieeexplore.ieee.org/abstract/document/9503377">H.266/VVC</a>, 
          Related Module: <a href="https://ieeexplore.ieee.org/abstract/document/9452121">Partition</span><br>
          [<a href="./files/PMPI/Partition Map-Based Fast Block Partitioning for VVC Inter Coding.pdf">PDF</a>] 
          [<a href="https://ieeexplore.ieee.org/abstract/document/11248955">DOI</a>] 
          [<a href="https://arxiv.org/abs/2504.18398">arXiv</a>]
          [<a href="https://github.com/ustc-ivclab/IPM">Code</a>]
        </td>
      </tr>

      <tr>
        <td style="line-height: 1.5;">
          <img src="./images/pic/DCVC-CM.png" width="200" height="100">
        </td>
        <td>
          <papertitle style="line-height: 1.5;"><a href="https://openaccess.thecvf.com/content/CVPR2025/html/Tang_Neural_Video_Compression_with_Context_Modulation_CVPR_2025_paper.html">
          Neural Video Compression with Context Modulation</a></papertitle> <br>
          Chuanbo Tang, <strong>Zhuoyuan Li</strong>, Yifan Bian, Li Li, and Dong Liu*<br>
          <em> Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em> (CVPR), 2025 <br>
          <span style="color: rgba(89, 0, 255, 0.753);">Related Codec: 
          <a href="https://proceedings.neurips.cc/paper_files/paper/2021/hash/96b250a90d3cf0868c83f8c965142d2a-Abstract.html">DCVC</a>,
          <a href="https://ieeexplore.ieee.org/abstract/document/9941493">TCM-VC</a>, 
          <a href="https://dl.acm.org/doi/abs/10.1145/3503161.3547845">DCVC-HEM</a>, 
          <a href="https://openaccess.thecvf.com/content/CVPR2023/html/Li_Neural_Video_Compression_With_Diverse_Contexts_CVPR_2023_paper.html">DCVC-DC</a>, 
          <a href="https://openaccess.thecvf.com/content/CVPR2024/html/Li_Neural_Video_Compression_with_Feature_Modulation_CVPR_2024_paper.html">DCVC-FM</a>,
          Related Module: 
          <a href="https://ieeexplore.ieee.org/abstract/document/8456249">Inter Prediction</a></span><br>
          [<a href="./files/DCVC-CM/DCVC-CM.pdf">PDF</a>]
          [<a href="https://arxiv.org/abs/2505.14541">arXiv</a>]
          [<a href="https://openaccess.thecvf.com/content/CVPR2025/html/Tang_Neural_Video_Compression_with_Context_Modulation_CVPR_2025_paper.html">DOI</a>]
          [<a href="./files/DCVC-CM/Poster_DCMVC.pdf">Poster</a>]  
          [<a href="./files/DCVC-CM/Valse_DCMVC.pdf">VALSE2025 Poster</a>]  
        </td>
      </tr>

      <tr>
        <td style="line-height: 1.5;">
          <img src="./images/pic/DCVC-RH.png" width="200" height="100">
        </td>
        <td>
          <papertitle style="line-height: 1.5;"><a href="https://openaccess.thecvf.com/content/CVPR2025/html/Tang_Neural_Video_Compression_with_Context_Modulation_CVPR_2025_paper.html">
          Neural Video Compression with Reference Hierarchy</a></papertitle> <br>
          Chuanbo Tang, <strong>Zhuoyuan Li</strong>, Li Li, Dong Liu*, and Feng Wu<br>
          <em> Proceedings of the AAAI Conference on Artificial Intelligence</em> (AAAI), Poster, 2026 <br>
          <span style="color: rgba(89, 0, 255, 0.753);">Related Codec: 
          <a href="https://proceedings.neurips.cc/paper_files/paper/2021/hash/96b250a90d3cf0868c83f8c965142d2a-Abstract.html">DCVC</a>,
          <a href="https://ieeexplore.ieee.org/abstract/document/9941493">TCM-VC</a>, 
          <a href="https://dl.acm.org/doi/abs/10.1145/3503161.3547845">DCVC-HEM</a>, 
          <a href="https://openaccess.thecvf.com/content/CVPR2023/html/Li_Neural_Video_Compression_With_Diverse_Contexts_CVPR_2023_paper.html">DCVC-DC</a>, 
          <a href="https://openaccess.thecvf.com/content/CVPR2024/html/Li_Neural_Video_Compression_with_Feature_Modulation_CVPR_2024_paper.html">DCVC-FM</a>,
          Related Module: 
          <a href="https://ieeexplore.ieee.org/abstract/document/8456249">Inter Prediction</a></span><br>
          [<a href="./images/pic/DCVC-RH.png">PDF</a>]
          [<a href="./images/pic/DCVC-RH.png">arXiv</a>]
          [<a href="./images/pic/DCVC-RH.png">DOI</a>]
          [<a href="./images/pic/DCVC-RH.png">Poster</a>]  
        </td>
      </tr>

      <tr>
        <td style="line-height: 1.5;">
          <img src="./images/pic/CDMVR-crop.png" width="200" height="60">
        </td>
        <td>
          <papertitle style="line-height: 1.5;"><a href="https://ieeexplore.ieee.org/abstract/document/11043848">
          Collaborative Decoder-side Motion Vector Refinement for Video Coding</a></papertitle> <br>
          Jialin Li, <strong>Zhuoyuan Li</strong>, Yao Li, Li Li*, and Houqiang Li<br>
          <em> IEEE International Symposium on Circuits and Systems</em> (ISCAS), Poster, 2025 <br>
          <span style="color: rgba(89, 0, 255, 0.753);">Related Codec: 
          <a href="https://ieeexplore.ieee.org/abstract/document/9428244">AOMedia Video 2 (AV2)</a>, 
          Related Module: 
          <a href="https://ieeexplore.ieee.org/abstract/document/8456249">Inter Prediction</a></span><br>
          [<a href="./files/CDMVR/Collaborative_Decoder-side_Motion_Vector_Refinement_for_Video_Coding.pdf">PDF</a>]
          [<a href="./files/CDMVR/CDMVR-poster.pdf">Poster</a>] 
          [<a href="https://ieeexplore.ieee.org/abstract/document/11043848">DOI</a>]
        </td>
      </tr>
    </tbody></table>

  <a id="services"></a><span class="section">Academic Services</span>
  <p></p>
  
  <strong>Reviewer of Journals:</strong>
  <ul>
    <li>
      <p style="line-height: 170%; margin-left: 15px; margin-top: 3pt; margin-bottom: 0pt;"><b>
        <font color="#000000" face='Lato' size="2"><b>
          IEEE Transactions on Image Processing  (TIP) </font></b></p>
    </li>

    <li>
      <p style="line-height: 170%; margin-left: 15px; margin-top: 3pt; margin-bottom: 0pt;"><b>
        <font color="#000000" face='Lato' size="2"><b>
          IEEE Transactions on Multimdeia (TMM) </font></b></p>
    </li>

    <li>
      <p style="line-height: 170%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;"><b>
        <font color="#000000" face='Lato' size="2"><b>
          IEEE Transactions on Circuits and Systems for Video Technology (TCSVT) </font></b></p>
    </li>

    <li>
      <p style="line-height: 170%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;"><b>
        <font color="#000000" face='Lato' size="2"><b>
          IEEE Transactions on Broadcasting (TBC) </font></b></p>
    </li>

    <li>
      <p style="line-height: 170%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;"><b>
        <font color="#000000" face='Lato' size="2"><b>
          ACM Transactions on Multimedia Computing, Communications, and Applications (TOMM) </font></b></p>
    </li>
  </ul>
  <p></p>
  Reviewer of Conferences:
  <ul>  
    <li>
      <p style="line-height: 150%; margin-left: 15px; margin-top: 4pt; margin-bottom: 0pt;"><b>
        <font color="#000000" face='Lato' size="2"><b>
          ACM International Conference on Multimedia (ACM MM 2022-2026)</font></b></p>
    </li>

    <li>
      <p style="line-height: 150%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;"><b>
        <font color="#000000" face='Lato' size="2"><b>
          Neural Information Processing Systems (NeurIPS 2024-2025)</font></b></p>
    </li>

    <li>
      <p style="line-height: 150%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;"><b>
        <font color="#000000" face='Lato' size="2"><b>
          International Conference on Computer Vision and Pattern Recognition  (CVPR 2026)</font></b></p>
    </li>

    <li>
      <p style="line-height: 150%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;"><b>
        <font color="#000000" face='Lato' size="2"><b>
          European Conference on Computer Vision (ECCV 2026)</font></b></p>
    </li>

    <li>
      <p style="line-height: 150%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;"><b>
        <font color="#000000" face='Lato' size="2"><b>
          Proceedings of the AAAI Conference on Artificial Intelligence (AAAI 2026)</font></b></p>
    </li>

    <li>
      <p style="line-height: 150%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;"><b>
        <font color="#000000" face='Lato' size="2"><b>
          International Conference on Learning Representations (ICLR 2025-2026)</font></b></p>
    </li>

    <li>
      <p style="line-height: 150%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;"><b>
        <font color="#000000" face='Lato' size="2"><b>
          International Conference on Machine Learning (ICML 2025-2026)</font></b></p>
    </li>

    <li>
      <p style="line-height: 150%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;"><b>
        <font color="#000000" face='Lato' size="2"><b>
          International Joint Conference on Artificial Intelligence (IJCAI 2025-2026)</font></b></p>
    </li>  
       
    <li>
      <p style="line-height: 150%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;"><b>
        <font color="#000000" face='Lato' size="2"><b>
          IEEE International Conference on Multimedia & Expo (ICME 2025-2026)</font></b></p>
    </li>

    <li>
      <p style="line-height: 150%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;"><b>
        <font color="#000000" face='Lato' size="2"><b>
          IEEE International Conference on Visual Communication and Image Processing Conference (VCIP 2023-2025)</font></b></p>
    </li>

    <li>
      <p style="line-height: 150%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;"><b>
        <font color="#000000" face='Lato' size="2"><b>
          Data Compression Conference  (DCC 2025-2026)</font></b></p>
    </li>
  </ul>

  <p><font color="#000000" face='Lato' size="2">&copy 2026.02.21 Zhuoyuan Li. Thanks to <a href="https://ruizhao26.github.io/">Dr. Rui Zhao, </a><a href="http://people.csail.mit.edu/celiu">Dr. Ce Liu</a> and 
  <a href="https://deqings.github.io/index.html">Dr. Deqing Sun</a> for the template.</p>

</body></html>
