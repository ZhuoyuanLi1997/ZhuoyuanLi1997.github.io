<!DOCTYPE html>
<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

<title>Zhuoyuan Li</title>
<meta content="Rui Zhao" name="Rui Zhao">
<link href="./zhuoyuan_files/style.css" rel="stylesheet" type="text/css">
<script src="./zhuoyuan_files/jquery-1.11.1.min.js" type="text/javascript"></script>  
</head>

<body>
  <div class="menu"> <a href="https://ZhuoyuanLi1997.github.io/index.html">Home</a> 
  <a href="https://ZhuoyuanLi1997.github.io/index.html#news">News</a> 
  <a href="https://ZhuoyuanLi1997.github.io/index.html#bio">Bio</a> 
  <a href="https://ZhuoyuanLi1997.github.io/index.html#education">Education</a>
  <a href="https://ZhuoyuanLi1997.github.io/index.html#publications">Publications</a>
  <a href="https://ZhuoyuanLi1997.github.io/index.html#Standard">Standardization</a>
  <a href="https://ZhuoyuanLi1997.github.io/index.html#Honors">Honors/Awards</a>
  <a href="https://ZhuoyuanLi1997.github.io/index.html#projects">Projects</a> 
  <a href="https://ZhuoyuanLi1997.github.io/index.html#services">Services</a>   
  </div>
  <div class="container">
    <table border="0" class="profile">
      <tbody><tr>
        <td><img src="./zhuoyuan_files/zhuoyuanli.JPG" width="160" height=""></td>
        <td style="width: 40px">&nbsp;</td>
        <td valign="top" width="800">
          <span class="name">Zhuoyuan Li (李卓元)</span>
          <p class="information"><br>
          Ph.D. Candidate,<br>
          <a href="https://ustc-ivclab.github.io/">intelligent Visual Data Coding Laboratory (iVC lab),</a> <br>
          <a href="https://en.sist.ustc.edu.cn/main.htm">Dept. EEIS, School of Information Science and Technology,</a><br>
          <a href="http://en.ustc.edu.cn/">University of Science and Technology of China (USTC)</a>.</p>

          <p class="information">No. 100 Fuxing Road, <br>
          Hefei, Anhui Province, China<br>
          Room 603 & 609, XinZhi Building, University of Science and Technology of China.
          <p class="information"><strong>E-mail</strong>: <span class="unselectable">zhuoayuanli</span>@mail.ustc.edu.cn</span> </p>
          <p class="information"><strong>WeChat</strong>: <span class="unselectable">ustc_lizhuoyuan </p>  
          <a href="https://scholar.google.com/citations?user=PiyMuF4AAAAJ&hl=zh-CN">Google Scholar</a> &nbsp;&nbsp;&nbsp;&nbsp;  
          <a href="https://www.linkedin.com/in/zhuoyuan-li-a03aa6276/">Linkedin</a> &nbsp;&nbsp;&nbsp;&nbsp;
          <a href="https://github.com/ZhuoyuanLi1997?tab=repositories">Github</a> &nbsp;&nbsp;&nbsp;&nbsp;
          <a href="https://orcid.org/0009-0003-7370-4068">ORCID</a> &nbsp;&nbsp;&nbsp;&nbsp;
        </td>
      </tr>
    </tbody></table>

    <a id="bio" class="anchor"></a>
    <span class="section">Breif Bio</span>
    <table border="0" class="bio" width="95%">
    <tr>
    <td width="80%">
      I am Zhuoyuan Li (Milk). I received the B.E. degree in Communication Engineering from the Southwest Jiaotong University, Sichuan, China, in 2020.
      I am currently pursuing the Ph.D. degree in Information and Communication Engineering with University of Science and Technology of China (USTC), Hefei, China, supervised by <a href="">Prof. Feng Wu</a> and <a href="">Prof. Dong Liu</a>. 
      I also worked closely with <a href="">Prof. Li Li</a> and many good friends from <a href="https://ustc-ivclab.github.io/">USTC-iVC</a> && <a href="https://vidar-ustc.github.io/">VIDAR</a> lab. My research interests include areas of <strong> Traditional Image/Video Coding</strong>, learned image/video compression
      and image/video processing, particularly for topics related to <strong>Inter Prediction</strong>, Intra Prediction, In-Loop Filtering, and Deep Learning-based Coding Tools in traditional codecs (H.266/VVC, H.265/HEVC).
    </td>
    </tr>
  </table>

    <a id="news" class="anchor"></a>
    <span class="section">News</span>
    <table border="0" class="news">
    <tr>
      <td>
        <p><strong>[2024.9]</strong> My homepage is open-sourced! </p>
      </td>
    </tr>
  </table>

    <a id="education" class="education"></a><span class="section">Education</span>
    <p class="education">
    <b>University of Science and Technology of China (USTC)</b>. <br>
    2020 - present, Ph.D., &nbsp; Information and Communication Engineering.       
    </p>
    <p class="education">
      <b>Southwest Jiaotong University (SWJTU)</b>. <br>
      2016 - 2020, &nbsp;&nbsp;&nbsp;   B.Eng., Communication Engineering.       
    </p>
      
    <!-- <p>&nbsp;</p> -->


    <!-- Publication session -->
    <a id="publications" class="anchor"></a><span class="section">Publications</a> </span>
    <table border="0" width="95%" class="paper" style="border-collapse:separate; border-spacing:10px;">
      <tbody>

      <tr>
        <td style="line-height: 1.5;">
          <img src="./images/pic/SAIP-crop.png" width="200" height="80">
        </td>
        <td>
          <papertitle style="line-height: 1.5;"> 
          <a href="https://ieeexplore.ieee.org/document/10623319"> 
          Object Segmentation-Assisted Inter Prediction for Versatile Video Coding</a></papertitle> <br>
          <strong>Zhuoyuan Li</strong>, Zikun Yuan, Li Li, Dong Liu*, Xiaohu Tang and Feng Wu <br>
          <em> IEEE Transactions on Broadcasting </em> (TBC), 2024 <br>
          <span style="color: rgba(89, 0, 255, 0.753);">Related Codec: H.266/VVC, Related Module: Inter Prediction</span><br>
          [<a href="https://openaccess.thecvf.com/content/CVPR2024/papers/Zhao_Boosting_Spike_Camera_Image_Reconstruction_from_a_Perspective_of_Dealing_CVPR_2024_paper.pdf">pdf</a>] 
          [<a href="https://ruizhao26.github.io/files/BSF_poster_git.pdf">poster</a>]
          [<a href="https://github.com/ruizhao26/BSF">DOI</a>]
          [<a href="https://github.com/ruizhao26/BSF">arXiv</a>]
        </td>
      </tr>

      <tr>
        <td style="line-height: 1.5;">
          <img src="./images/pic/SAIP-crop.png" width="200" height="80">
        </td>
        <td>
          <papertitle style="line-height: 1.5;"> 
          <a href="https://ieeexplore.ieee.org/document/10623319"> 
            USTC-TD: A Test Dataset and Benchmark for Image and Video Coding in 2020s</a></papertitle> <br>
          <strong>Zhuoyuan Li</strong>, Junqi Liao (Co-first), Chuanbo Tang, Haotian Zhang, Yuqi Li, Yifan Bian, Xihua Sheng, Xinmin Feng, Yao Li, Changsheng Gao, Li Li, Dong Liu*, and Feng Wu <br>
          <em> arXiv Preprint, (arXiv:2407.11541), </em> 2024 <br>
          <span style="color: rgba(89, 0, 255, 0.753);">Related Traditional Codec: H.266/VVC, H.265/HEVC, BPG</span><br>
          <span style="color: rgba(89, 0, 255, 0.753);">Related End-to-End Image Codec: iWave++, Factorized Model, Hyperprior Model, Autoregressive Model, Cheng2020, ELIC, MLIC++</span><br>
          <span style="color: rgba(89, 0, 255, 0.753);">Related End-to-End Video Codec: DVC_Pro, DCVC, CANF-VC, TCM-VC, DCVC-HEM, OOFE, VNVC, SDD, DCVC-DC, DCVC-FM</span><br>
          [<a href="https://openaccess.thecvf.com/content/CVPR2024/papers/Zhao_Boosting_Spike_Camera_Image_Reconstruction_from_a_Perspective_of_Dealing_CVPR_2024_paper.pdf">pdf</a>] 
          [<a href="https://ruizhao26.github.io/files/BSF_poster_git.pdf">poster</a>]
          [<a href="https://github.com/ruizhao26/BSF">DOI</a>]
          [<a href="https://github.com/ruizhao26/BSF">arXiv</a>]
        </td>
      </tr>

      <tr>
        <td style="line-height: 1.5;">
          <img src="./images/pubpic/aaai2024.png" width="200" height="80">
        </td>
        <td>
          <papertitle style="line-height: 1.5;"><a href="https://ojs.aaai.org/index.php/AAAI/article/view/28581">
            Uniformly Accelerated Motion Model for Inter Prediction</a></papertitle> <br>
          <strong>Zhuoyuan Li</strong>, Yao Li, Chuanbo Tang, Li Li, Dong Liu*, and Feng Wu<br>
          <em> arXiv Preprint, (arXiv:2407.11541), </em> 2024 <br>
          <span style="color: rgba(89, 0, 255, 0.753);">Related Codec: H.266/VVC, Related Module: Inter Prediction</span><br>
          [<a href="https://ojs.aaai.org/index.php/AAAI/article/view/28581/29130">pdf</a>] 
          [<a href="https://ruizhao26.github.io/files/HiST-SFlow_poster_git.pdf">poster</a>]
        </td>
      </tr>

      <tr>
        <td style="line-height: 1.5;">
          <img src="./images/pubpic/aaai2024.png" width="200" height="80">
        </td>
        <td>
          <papertitle style="line-height: 1.5;"><a href="https://ojs.aaai.org/index.php/AAAI/article/view/28581">
            In-Loop Filtering via Trained Look-Up Tables</a></papertitle> <br>
          <strong>Zhuoyuan Li</strong>, Jiacheng Li, Yao Li, Li Li, Dong Liu*, and Feng Wu<br>
          <em> arXiv Preprint, (arXiv:2407.10926), </em> 2024 <br>
          <span style="color: rgba(89, 0, 255, 0.753);">Related Codec: H.266/VVC, Related Module: In-Loop Filtering</span><br>
          [<a href="https://ojs.aaai.org/index.php/AAAI/article/view/28581/29130">pdf</a>] 
          [<a href="https://ruizhao26.github.io/files/HiST-SFlow_poster_git.pdf">poster</a>]
        </td>
      </tr>

      <tr>
        <td style="line-height: 1.5;">
          <img src="./images/pubpic/csvt2023.png" width="200" height="80">
        </td>
        <td>
          <papertitle style="line-height: 1.5;"><a href="https://ieeexplore.ieee.org/abstract/document/10288531">
          Global Homography Motion Compensation for Versatile Video Coding</a></papertitle> <br>
          Yao Li, <strong>Zhuoyuan Li</strong>, Li Li*, Dong Liu, and Houqiang Li<br>
          <em> IEEE International Conference on Visual Communications and Image Processing</em> (VCIP), 2022 <br>
          <span style="color: rgba(89, 0, 255, 0.753);">Related Codec: H.266/VVC, Related Module: Inter Prediction</span><br>
          [<a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10288531">pdf</a>]
        </td>
      </tr>

      <tr>
        <td style="line-height: 1.5;">
          <img src="./images/pubpic/usflow.png" width="200" height="80">
        </td>
        <td>
          <papertitle style="line-height: 1.5;"><a href="https://openreview.net/forum?id=7gbjsgcN5p">
          Rethinking the Joint Optimization in Video Coding for Machines: A Case Study</a></papertitle> <br>
          Changsheng Gao, <strong>Zhuoyuan Li</strong>, Li Li, Dong Liu* and Feng Wu <br>
          <em> Data Compression Conference </em> (DCC), 2024 <br>
          <span style="color: rgba(89, 0, 255, 0.753);">Related Codec: Feature Compression, Related Module: Joint Optimization</span><br>
          [<a href="https://openreview.net/pdf?id=7gbjsgcN5p">pdf</a>] 
          [<a href="https://arxiv.org/abs/2307.06003.pdf">arxiv</a>] 
        </td>
      </tr>

      <tr>
        <td style="line-height: 1.5;">
          <img src="./images/pubpic/usflow.png" width="200" height="80">
        </td>
        <td>
          <papertitle style="line-height: 1;"><a href="https://openreview.net/forum?id=7gbjsgcN5p">
          Temporal Wavelet Transform-Based Low-Complexity Perceptual Quality Enhancement of Compressed Video</a></papertitle> <br>
          Cunhui Dong, Haichuan Ma (Co-first), <strong>Zhuoyuan Li</strong>, Li Li, and Dong Liu*<br>
          <em> IEEE Transactions on Circuits and Systems for Video Technology </em> (TCSVT), 2024 <br>
          <span style="color: rgba(89, 0, 255, 0.753);">Related Codec: H.266/VVC, H.265/HEVC, Related Module: Post-Processing</span><br>
          [<a href="https://openreview.net/pdf?id=7gbjsgcN5p">pdf</a>] 
          [<a href="https://arxiv.org/abs/2307.06003.pdf">arxiv</a>] 
        </td>
      </tr>

      <tr>
        <td style="line-height: 1.5;">
          <img src="./images/pubpic/usflow.png" width="200" height="80">
        </td>
        <td>
          <papertitle style="line-height: 1.5;"><a href="https://openreview.net/forum?id=7gbjsgcN5p">
          IVCA: Inter-Relation-Aware Video Complexity Analyzer</a></papertitle> <br>
          Junqi Liao, Yao Li (Co-first), <strong>Zhuoyuan Li</strong>, Li Li*, and Dong Liu<br>
          <em> arXiv Preprint, (arXiv:2407.00280) </em>, 2024 <br>
          <span style="color: rgba(255, 0, 0, 0.904);">Project Report for ICIP 2024 Grand Challenge on Video Complexity, <br>Wining Team (USTC-iVC1) and 1st Runner-up Team (USTC-iVC2)</span><br>
          <span style="color: rgba(89, 0, 255, 0.753);">Related Codec: Video Complexity Analyzer (VCA), Related Module: Inter-frame Relation Modeling</span><br>
          [<a href="https://openreview.net/pdf?id=7gbjsgcN5p">pdf</a>] 
          [<a href="https://arxiv.org/abs/2307.06003.pdf">arxiv</a>] 
        </td>
      </tr>


      <tr>
        <td style="line-height: 1.5;">
          <img src="./images/pubpic/usflow.png" width="200" height="80">
        </td>
        <td>
          <papertitle style="line-height: 1.5;"><a href="https://openreview.net/forum?id=7gbjsgcN5p">
          Offline and Online Optical Flow Enhancement for Deep Video Compression</a></papertitle> <br>
          Chuanbo Tang, Xihua Sheng, <strong>Zhuoyuan Li</strong>, Haotian Zhang, Li Li, and Dong Liu*<br>
          <em> Proceedings of the AAAI Conference on Artificial Intelligence </em> (AAAI), 2024 <br>
          <span style="color: rgba(89, 0, 255, 0.753);">Related Codec: Deep Contextual Video Compression (DCVC), Related Module: Inter Prediction</span><br>
          [<a href="https://openreview.net/pdf?id=7gbjsgcN5p">pdf</a>] 
          [<a href="https://arxiv.org/abs/2307.06003.pdf">arxiv</a>] 
        </td>
      </tr>
    </tbody></table>
    <!-- <p>&nbsp;</p> -->
    
    <!-- Publication session -->
    <a id="Standard" class="anchor"></a><span class="section">Standardization Activities</a> </span>
    <table border="0" width="95%" class="paper" style="border-collapse:separate; border-spacing:10px;">
      <tbody>
        <tr>
          <td style="line-height: 1.5;">
            <img src="./images/pubpic/mowe.png" width="200" height="100">
          </td>
          <td>
            <papertitle style="line-height: 1.5;"><a href="https://arxiv.org/abs/2303.13739">
            Proposal for Intra Pattern Copy of JPEG XS Screen Content Image Coding</a></papertitle><br>
            <em><strong>JPEG XS</strong>, ISO/IEC JTC 1/SC 29/WG 1</em>, wg1m104003, 2024<br>
            Yao Li, <strong>Zhuoyuan Li</strong>, Li Li, Dong Liu<br>
            Proposal Organization: University of Science and Technology of China (USTC)<br>
            [<a href="https://arxiv.org/pdf/2303.13739.pdf">pdf</a>]
          </td>
        </tr>

        <tr>
          <td style="line-height: 1.5;">
            <img src="./images/pubpic/mowe.png" width="200" height="100">
          </td>
          <td>
            <papertitle style="line-height: 1.5;"><a href="https://arxiv.org/abs/2303.13739">
            New Use Cases and Requirements</a></papertitle><br>
            <em><strong>JPEG XS</strong>, ISO/IEC JTC 1/SC 29/WG 1</em>, wg1m104074, 2024<br>
            Yao Li, <strong>Zhuoyuan Li</strong>, Li Li, Dong Liu<br>
            Proposal Organization: University of Science and Technology of China (USTC)<br>
            [<a href="https://arxiv.org/pdf/2303.13739.pdf">pdf</a>]
          </td>
        </tr>

        <tr>
          <td style="line-height: 1.5;">
            <img src="./images/pubpic/mowe.png" width="200" height="100">
          </td>
          <td>
            <papertitle style="line-height: 1.5;"><a href="https://arxiv.org/abs/2303.13739">
            一种用于稳定EEM训练的验证集USTC-TD</a></papertitle><br>
            <em><strong>AVS 90#</strong>, 威海</em>, M8526, 2024<br>
            唐传波，卞逸凡，盛锡华，<strong>李卓元</strong>，李礼，刘东<br>
            Proposal Organization: University of Science and Technology of China (USTC)<br>
            [<a href="https://arxiv.org/pdf/2303.13739.pdf">pdf</a>]
          </td>
        </tr>
    </tbody></table>

    <!-- Publication session -->
    <a id="Honors" class="anchor"></a><span class="section">Honors and Awards</a> </span>
    <table border="0" width="95%" class="paper" style="border-collapse:separate; border-spacing:10px;">
      <tbody>
        <tr>
          <td style="line-height: 1.5;">
            <img src="./images/pubpic/mowe.png" width="200" height="100">
          </td>
          <td>
            <papertitle style="line-height: 1.5;"><a href="https://arxiv.org/abs/2303.13739">
            Grand Challenge on "Video Complexity"</a></papertitle><br>
            <em> IEEE International Conference on Image Processing</em> (ICIP), 2024<br>
            <span style="color: rgba(255, 0, 0, 0.904);"><strong>Winner Prize</strong></span>,
            Team: USTC-iVC1<br>
            Junqi Liao, Yao Li, <strong>Zhuoyuan Li</strong><br>
            Advisor: Li Li, Dong Liu<br>
            [<a href="https://arxiv.org/pdf/2303.13739.pdf">pdf</a>]
          </td>
        </tr>

        <tr>
          <td style="line-height: 1.5;">
            <img src="./images/pubpic/mowe.png" width="200" height="100">
          </td>
          <td>
            <papertitle style="line-height: 1.5;"><a href="https://arxiv.org/abs/2303.13739">
            Grand Challenge on "Video Complexity"</a></papertitle> <br>
            <em> IEEE International Conference on Image Processing</em> (ICIP), 2024<br>
            <span style="color: rgba(255, 0, 0, 0.904);"><strong>1st Runner-up Prize</strong></span>,
            Team: USTC-iVC2<br>
            Yao Li, Junqi Liao, <strong>Zhuoyuan Li</strong><br>
            Advisor: Li Li, Dong Liu<br>
            [<a href="https://arxiv.org/pdf/2303.13739.pdf">pdf</a>]
          </td>
        </tr>

        <tr>
          <td style="line-height: 1.5;">
            <img src="./images/pubpic/mowe.png" width="200" height="100">
          </td>
          <td>
            <papertitle style="line-height: 1.5;"><a href="https://arxiv.org/abs/2303.13739">
            Grand Challenge on "End-to-End Practical Video Compression"</a></papertitle> <br>
            <em> IEEE International Conference on Visual Communications and Image Processing</em> (VCIP), 2023<br>
            <span style="color: rgba(255, 0, 0, 0.904);"><strong>1st Runner-up Prize</strong></span>, Team: BOotingFANtasticalLY<br>
            Yifan Bian, Chuanbo Tang, Yao Li, <strong>Zhuoyuan Li</strong><br>
            Advisor: Li Li, Dong Liu<br>
            [<a href="https://arxiv.org/pdf/2303.13739.pdf">pdf</a>]
          </td>
        </tr>
        
        <!-- <tr>
          <td style="line-height: 1.5;">
            <img src="./images/pubpic/mowe.png" width="200" height="100">
          </td>
          <td>
            <papertitle style="line-height: 1.5;"><a href="https://arxiv.org/abs/2303.13739">
            Grand Challenge on "End-to-End Practical Image Compression"</a></papertitle> <br>
            <em> International Workshop on Multimedia Signal Processing</em> (MMSP), 2024<br>
            Team: iVC<br>
          </td>
        </tr> -->
 
        <!-- <tr>
          <td style="line-height: 1.5;">
            <img src="./images/pubpic/mowe.png" width="200" height="100">
          </td>
          <td>
            <papertitle style="line-height: 1.5;"><a href="https://arxiv.org/abs/2303.13739">
            Grand Challenge on "End-to-End Practical Video Compression"</a></papertitle> <br>
            <em> International Workshop on Multimedia Signal Processing</em> (MMSP), 2024<br>
            Team: iVC<br>
          </td>
        </tr> -->

        <tr>
          <td style="line-height: 1.5;">
            <img src="./images/pubpic/mowe.png" width="200" height="100">
          </td>
          <td>
            <papertitle style="line-height: 1.5;"><a href="https://arxiv.org/abs/2303.13739">
            Undergraduate Thesis of Southwest Jiaotong University</a></papertitle> <br>
            <em> Southwest Jiaotong University</em> (SWJTU), 2018<br>
            <span style="color: rgba(255, 0, 0, 0.904);"><strong>Best Undergraduate Thesis, 1/93</span></strong><br> 
            Thesis Topic: Deep Learning-based Combined Intra and Inter Prediction for Versatile Video Coding<br>
            <strong>Zhuoyuan Li</strong><br>
            USTC Advisor: Dong Liu, Feng Wu
          </td>
        </tr>

        <tr>
          <td style="line-height: 1.5;">
            <img src="./images/pubpic/mowe.png" width="200" height="100">
          </td>
          <td>
            <papertitle style="line-height: 1.5;"><a href="https://arxiv.org/abs/2303.13739">
            China Undergraduate Mathematical Contest in Modeling</a></papertitle> <br>
            <em> China Society for Industrial and Applied Mathematics</em> (CSIAM), 2018<br>
            <span style="color: rgba(255, 0, 0, 0.904);"><strong>National First-Prize Winner</span></strong>, Team: Southwest Jiaotong University (SWJTU)<br>
            <strong>Zhuoyuan Li</strong>, Zongmou Li, Jinhong He<br>
            Advisor: Lu Wang
          </td>
        </tr>
    </tbody></table>

   <!-- Publication session -->
   <a id="projects" class="anchor"></a><span class="section">Projects</a> </span>
   <table border="0" width="95%" class="paper" style="border-collapse:separate; border-spacing:10px;">
     <tbody>

     <tr>
      <td>
      &nbsp; &nbsp; &nbsp; &nbsp;
      </td>
       <td>
         <img src="./images/pubpic/spikecv_logo_new.png" width="100" height="120">
       </td>
       <td>
        &nbsp; &nbsp; &nbsp; &nbsp;
       </td>

       <td>
         <papertitle><a href="https://git.openi.org.cn/Cordium/SpikeCV">
         SpikeCV: An Open-Source Framework for Spike Vision</a></papertitle> <br>
         Yajing Zheng, Jiyuan Zhang, <strong>Rui Zhao</strong>, Jianhao Ding, Shiyan Chen, and et al. <br>
         <!-- <em> Annual Conference on Neural Information Processing Systems </em> (<strong>NeurIPS</strong>) 2022 <br> -->
         [<a href="https://spikecv.github.io">Website</a>]
         [<a href="https://spikecv.github.io/zh/index.html">Website(CN)</a>]
         [<a href="https://git.openi.org.cn/Cordium/SpikeCV">Openi-Git(CN)</a>]
         [<a href="https://github.com/Zyj061/SpikeCV">Github</a>]
         [<a href="https://arxiv.org/pdf/2303.11684.pdf">pdf</a>]
       </td>
     </tr>
   </tbody></table>
   <!-- <p>&nbsp;</p> -->
  
  <a id="projects" class="anchor"></a><span class="section">Projects</a> </span>
  <table border="0" width="95%" class="paper" style="border-collapse:separate; border-spacing:10px;">
  <ul>
    <li>
      <p style="line-height: 150%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;"><b>
        <font color="#000000" face='Lato' size="2"><font color="#000000" face='Lato' size="2"><b><font color="#000000" face='Lato'>
          Industrial Bank Scholarship, 2023</font></b></font></font></b></p>
    </li>

    <li>
      <p style="line-height: 150%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;"><b>
        <font color="#000000" face='Lato' size="2"><font color="#000000" face='Lato' size="2"><b><font color="#000000" face='Lato'>
          UbiQuant Scholarship, 2022</font></b></font></font></b></p>
    </li>
    
    <li>
      <p style="line-height: 150%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;"><b>
        <font color="#000000" face='Lato' size="2"><font color="#000000" face='Lato' size="2"><b><font color="#000000" face='Lato'>
          President Scholarship for Ph.D. Student of Peking University (2%), 2022</font></b></font></font></b></p>
    </li>

    <li>
      <p style="line-height: 150%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;"><b>
        <font color="#000000" face='Lato' size="2"><font color="#000000" face='Lato' size="2"><b><font color="#000000" face='Lato'>
          President Scholarship for Ph.D. Student of Peking University (2%), 2021</font></b></font></font></b></p>
    </li>

    <li>
      <p style="line-height: 150%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;"><b>
        <font color="#000000" face='Lato' size="2"><font color="#000000" face='Lato' size="2"><b><font color="#000000" face='Lato'>
          President Scholarship for Ph.D. Student of Peking University (2%), 2020</font></b></font></font></b></p>
    </li>

    <li>
      <p style="line-height: 150%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;"><b>
        <font color="#000000" face='Lato' size="2"><font color="#000000" face='Lato' size="2"><b><font color="#000000" face='Lato'>
          Outstanding Student Model Honorable Mention Scholarship of Tianjin University (0.05%), 2019</font></b></font></font></b></p>
    </li>

    <li>
      <p style="line-height: 150%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;"><b>
        <font color="#000000" face='Lato' size="2"><font color="#000000" face='Lato' size="2"><b><font color="#000000" face='Lato'>
          National Scholarship for Bachelor Student of Tianjin University (2%), 2019</font></b></font></font></b></p>
    </li>

    <li>
      <p style="line-height: 150%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;"><b>
        <font color="#000000" face='Lato' size="2"><font color="#000000" face='Lato' size="2"><b><font color="#000000" face='Lato'>
          National Scholarship for Bachelor Student of Tianjin University (2%), 2018</font></b></font></font></b></p>
    </li>
  </ul>
  </font>
  <!-- <p>&nbsp;</p> -->

  <a id="services"></a><span class="section">Academic Services</span>
  <strong>Reviewer of Journals:</strong>
  <ul>
    <li>
      <p style="line-height: 170%; margin-left: 15px; margin-top: 3pt; margin-bottom: 0pt;"><b>
        <font color="#000000" face='Lato' size="2"><b>
          IEEE Transactions on Image Processing  (TIP) </font></b></p>
    </li>

    <li>
      <p style="line-height: 170%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;"><b>
        <font color="#000000" face='Lato' size="2"><b>
          IEEE Transactions on Circuits and Systems for Video Technology (TCSVT) </font></b></p>
    </li>

    <li>
      <p style="line-height: 170%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;"><b>
        <font color="#000000" face='Lato' size="2"><b>
          IEEE Transactions on Broadcasting (TBC) </font></b></p>
    </li>
    
    <li>
      <p style="line-height: 170%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;"><b>
        <font color="#000000" face='Lato' size="2"><b>
          IEEE Internet Things of Journal (IOT) </font></b></p>
    </li>
  </ul>
  <p></p>
  <strong>Reviewer of Conferences:</strong>
  <ul>  
    <li>
      <p style="line-height: 150%; margin-left: 15px; margin-top: 4pt; margin-bottom: 0pt;"><b>
        <font color="#000000" face='Lato' size="2"><b>
          ACM International Conference on Multimedia (ACM MM 2022)</font></b></font></font></b></p>
    </li>

    <li>
      <p style="line-height: 150%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;"><b>
        <font color="#000000" face='Lato' size="2"><b>
          ACM International Conference on Multimedia (ACM MM 2023)</font></b></font></font></b></p>
    </li>

    <li>
      <p style="line-height: 150%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;"><b>
        <font color="#000000" face='Lato' size="2"><b>
          ACM International Conference on Multimedia (ACM MM 2024)</font></b></font></font></b></p>
    </li>

    <li>
      <p style="line-height: 150%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;"><b>
        <font color="#000000" face='Lato' size="2"><b>
          Neural Information Processing Systems (NeurIPS 2024)</font></b></font></font></b></p>
    </li>

    <li>
      <p style="line-height: 150%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;"><b>
        <font color="#000000" face='Lato' size="2"><b>
          IEEE International Workshop on Multimedia Signal Processing (MMSP 2024)</font></b></font></font></b></p>
    </li>

    <li>
      <p style="line-height: 150%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;"><b>
        <font color="#000000" face='Lato' size="2"><b>
          IEEE International Conference on Visual Communication and Image Processing Conference (VCIP 2023)</font></b></font></font></b></p>
    </li>

    <li>
      <p style="line-height: 150%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;"><b>
        <font color="#000000" face='Lato' size="2"><b>
          IEEE International Conference on Visual Communication and Image Processing Conference (VCIP 2024)</font></b></font></font></b></p>
    </li>

    <li>
      <p style="line-height: 150%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;"><b>
        <font color="#000000" face='Lato' size="2"><b>
          International Conference on Wireless Communications and Signal Processing (WCSP 2024)</font></b></font></font></b></p>
    </li>

    <li>
      <p style="line-height: 150%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;"><b>
        <font color="#000000" face='Lato' size="2"><b>
          International Conference on Acoustics, Speech and Signal Processing  (ICASSP 2025)</font></b></font></font></b></p>
    </li>

    <li>
      <p style="line-height: 150%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;"><b>
        <font color="#000000" face='Lato' size="2"><b>
          International Conference on Learning Representations (ICLR 2025)</font></b>
    </li>

  </ul>

  </font>
  </ul>

  <a id="projects" class="anchor"></a><span class="section">Participant Conference</a> </span>
  <table border="0" width="95%" class="paper" style="border-collapse:separate; border-spacing:10px;">
  <ul>
    <li>
      <p style="line-height: 150%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;"><b>
      <font color="#000000" face='Lato' size="2"><b>
        (Next Plan) IEEE International Conference on Image Processing (ICIP 2024), Abu Dhabi, United Arab Emirates</font></b></p>
    </li>
    <li>
      <p style="line-height: 150%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;"><b>
        <font color="#000000" face='Lato' size="2"><b>
        IEEE International Conference on Image Processing (ICIP 2023), Kuala Lumpur, Malaysia</font></b></p>
    </li>
    <li>
      <p style="line-height: 150%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;"><b>
      <font color="#000000" face='Lato' size="2"><b>
      IEEE International Conference on Visual Communications and Image Processing (VCIP 2023), Jeju, Korea</font></b></p>
    </li>
    <li>
      <p style="line-height: 150%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;"><b>
      <font color="#000000" face='Lato' size="2"><b>
      China Multimedia (ChinaMM 2024), Yinchuan, China</font></b></p>
    </li>
    <li>
      <p style="line-height: 150%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;"><b>
      <font color="#000000" face='Lato' size="2"><b>
      Vision and Learning Seminar (VALSE 2024), Chongqing, China</font></b></p>
    </li>
    <li>
      <p style="line-height: 150%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;"><b>
      <font color="#000000" face='Lato' size="2"><b>
      Chinese Congress on Image and Graphics (CCIG 2024), Xi'an, China</font></b></p>
    </li>
    <li>
      <p style="line-height: 150%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;"><b>
      <font color="#000000" face='Lato' size="2"><b>
        空间信息技术及产业发展大会 2024, Hefei, China</font></b></p>
    </li>
    <li>
      <p style="line-height: 150%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;"><b>
      <font color="#000000" face='Lato' size="2"><b>
        人工智能前沿论坛 2024, Hefei, China</font></b></p>
    </li>
  </ul>

  <!-- <p>&nbsp;</p> -->

  <p><font color="#000000" face='Lato' size="2">&copy 2024 Zhuoyuan Li. Thanks to <a href="http://people.csail.mit.edu/celiu"><font color="#000080">Dr. Rui Zhao, </font></a><a href="http://people.csail.mit.edu/celiu"><font color="#000080">Dr. Ce Liu</font></a> and 
  <a href="https://deqings.github.io/index.html"><font color="#000080">Dr. Deqing Sun</font></a> for the template. </font></p>

</body></html>
