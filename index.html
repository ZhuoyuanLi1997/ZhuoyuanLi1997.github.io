<!DOCTYPE html>
<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">



<title>Zhuoyuan Li</title>
<meta content="Rui Zhao" name="Rui Zhao">
<link href="./zhuoyuan_files/style.css" rel="stylesheet" type="text/css">
<script src="./zhuoyuan_files/jquery-1.11.1.min.js" type="text/javascript"></script>  
</head>

<body>
  <div class="menu"> <a href="https://ZhuoyuanLi1997.github.io/index.html">Home</a> 
  <a href="https://ZhuoyuanLi1997.github.io/index.html#news">News</a> 
  <a href="https://ZhuoyuanLi1997.github.io/index.html#bio">Bio</a> 
  <a href="https://ZhuoyuanLi1997.github.io/index.html#education">Education</a>
  <a href="https://ZhuoyuanLi1997.github.io/index.html#publications">Publications</a>
  <a href="https://ZhuoyuanLi1997.github.io/index.html#Honors">Honors/Awards</a>
  <a href="https://ZhuoyuanLi1997.github.io/index.html#Standard">Standardization</a>
  <a href="https://ZhuoyuanLi1997.github.io/index.html#projects">Projects</a> 
  <a href="https://ZhuoyuanLi1997.github.io/index.html#services">Services</a>   
  <a href="https://ZhuoyuanLi1997.github.io/index.html#Talks">Talks</a> 
  </div>
  <div class="container">
    <table border="0" class="profile">
      <tbody><tr>
        <td><img src="./zhuoyuan_files/zhuoyuanli.JPG" width="160" height=""></td>
        <td style="width: 40px">&nbsp;</td>
        <td valign="top" width="800">
          <span class="name">Zhuoyuan Li (李卓元)</span>
          <p class="information"><br>
          Ph.D. Candidate,<br>
          <a href="https://ustc-ivclab.github.io/">intelligent Visual Data Coding Laboratory (iVC lab),</a> <br>
          <a href="https://en.sist.ustc.edu.cn/main.htm">Dept. EEIS, School of Information Science and Technology,</a><br>
          <a href="http://en.ustc.edu.cn/">University of Science and Technology of China (USTC)</a>.</p>

          <p class="information">No. 100 Fuxing Road, <br>
          Hefei, Anhui Province, China<br>
          Room 603 & 609, XinZhi Building, University of Science and Technology of China.
          <p class="information"><strong>E-mail</strong>: <span class="unselectable">zhuoyuanli</span>@mail.ustc.edu.cn</span> </p>
          <p class="information"><strong>WeChat</strong>: <span class="unselectable">ustc_lizhuoyuan </p>  
          <a href="https://scholar.google.com/citations?user=PiyMuF4AAAAJ&hl=zh-CN">Google Scholar</a> &nbsp;&nbsp;&nbsp;&nbsp;  
          <a href="https://www.linkedin.com/in/zhuoyuan-li-a03aa6276/">Linkedin</a> &nbsp;&nbsp;&nbsp;&nbsp;
          <a href="https://github.com/ZhuoyuanLi1997?tab=repositories">Github</a> &nbsp;&nbsp;&nbsp;&nbsp;
          <a href="https://dblp.org/pid/81/2220-1.html">DBLP</a> &nbsp;&nbsp;&nbsp;&nbsp;
          <a href="https://orcid.org/0009-0003-7370-4068">ORCID</a> &nbsp;&nbsp;&nbsp;&nbsp;
          <a href="https://openreview.net/profile?id=~Zhuoyuan_Li2">OpenReview</a> &nbsp;&nbsp;&nbsp;&nbsp;
          <a href="./files/CV/lzy-Resume.pdf">CV</a> &nbsp;&nbsp;&nbsp;&nbsp;
        </td>
      </tr>
    </tbody></table>

    <a id="bio" class="anchor"></a>
    <span class="section">Brief Bio</span>
    <table border="0" class="bio" width="95%">
    <tr>
    <td width="80%">
      I am Zhuoyuan Li (Milk). I received the B.E. degree in Communication Engineering from the Southwest Jiaotong University, Sichuan, China, in 2020.
      I am currently pursuing the Ph.D. degree in Information and Communication Engineering with University of Science and Technology of China (USTC), Hefei, China, supervised by <a href="https://scholar.google.com/citations?user=5bInRDEAAAAJ&hl=zh-CN&oi=ao">Prof. Feng Wu</a> and <a href="https://faculty.ustc.edu.cn/dongeliu/">Prof. Dong Liu</a>. 
      I also worked closely with <a href="https://faculty.ustc.edu.cn/lil1/en">Prof. Li Li</a> and many good friends from <a href="https://ustc-ivclab.github.io/">USTC-iVC</a> && <a href="https://vidar-ustc.github.io/">VIDAR</a> lab. My research interests include areas of <strong> Traditional Image/Video Coding</strong>, learned image/video compression
      and image/video processing, particularly for topics related to <strong>Inter Prediction</strong>, Intra Prediction, In-Loop Filtering, and Deep Learning-based Coding Tools in traditional codecs (H.266/VVC, AV2, H.265/HEVC).
    </td>
    </tr>
  </table>

    <a id="news" class="anchor"></a>
    <span class="section">News</span>
    <table border="0" class="news">
    <tr>
      <td>
        <p><strong>[2025.11]</strong> Awarded champion in the IEEE VCIP 2025 competition </p>
        <p><strong>[2025.11]</strong> Awarded outstanding exploration award in the PRCV 2025 competition </p>
        <p><strong>[2025.11]</strong> Invited as the reviewer for ICME 2026. </p>
        <p><strong>[2025.11]</strong> One cooperated paper is accepted by AAAI 2026. </p>
        <p><strong>[2025.10]</strong> Elected as the Top Reviewer of NeurIPS 2025.</p>
        <p><strong>[2025.10]</strong> One paper is accepted by VCIP 2025. </p>
        <p><strong>[2025.09]</strong> Invited as the reviewer for ICLR 2026. </p>
      </td>
    </tr>
  </table>

    <a id="education" class="education"></a><span class="section">Education</span>
    <p class="education">
    <b>University of Science and Technology of China (USTC)</b>. <br>
    2020 - present, Ph.D., &nbsp; Information and Communication Engineering.       
    </p>
    <p class="education">
      <b>Southwest Jiaotong University (SWJTU)</b>. <br>
      2016 - 2020, &nbsp;&nbsp;&nbsp;   B.Eng., Communication Engineering.       
    </p>
    <p class="education">
      <b>The Middle, Primary School Attached To Northwestern Polytechnical University (NWPU)</b>. <br>
      2004 - 2016, &nbsp;&nbsp;&nbsp;   School Student.      
    </p>
      
    <a id="publications" class="anchor"></a><span class="section">Publications</a> </span>
    <table border="0" width="95%" class="paper" style="border-collapse:separate; border-spacing:10px;">
      <tbody>

      <tr>
        <td style="line-height: 1.5;">
          <img src="./images/pic/SAIP-crop.png" width="200" height="100">
        </td>
        <td>
          <papertitle style="line-height: 1.5;"> 
          <a href="https://ieeexplore.ieee.org/document/10623319"> 
          Object Segmentation-Assisted Inter Prediction for Versatile Video Coding</a></papertitle> <br>
          <strong>Zhuoyuan Li</strong>, Zikun Yuan, Li Li, Dong Liu*, Xiaohu Tang, and Feng Wu <br>
          <em> IEEE Transactions on Broadcasting </em> (TBC), 2024 <br>
          <span style="color: rgba(89, 0, 255, 0.753);">Related Codec: 
          <a href="https://ieeexplore.ieee.org/abstract/document/9503377">H.266/VVC</a>, 
          Related Module: 
          <a href="https://ieeexplore.ieee.org/abstract/document/9502124">Inter Prediction</a></span><br>
          [<a href="./files/SAIP/SAIP-TBC.pdf">PDF</a>] 
          [<a href="https://ieeexplore.ieee.org/document/10623319">DOI</a>]
          [<a href="https://arxiv.org/abs/2403.11694">arXiv</a>]
        </td>
      </tr>

      <tr>
        <td style="line-height: 1.5;">
          <img src="./images/pic/ustc-td-crop.png" width="200" height="130">
        </td>
        <td>
          <papertitle style="line-height: 1.5;"> 
          <a href="https://esakak.github.io/USTC-TD/"> USTC-TD: A Test Dataset and Benchmark for Image and Video Coding in 2020s</a></papertitle> <br>
          <strong>Zhuoyuan Li</strong>, Junqi Liao (Co-first), Chuanbo Tang, Haotian Zhang, Yuqi Li, Yifan Bian, Xihua Sheng, Xinmin Feng, Yao Li, Changsheng Gao, Li Li, Dong Liu*, and Feng Wu* <br>
          <em> IEEE Transactions on Multimedia</em> (TMM), 2025 <br>
          <span style="color: rgba(89, 0, 255, 0.753);">Related Traditional Codec: 
          <a href="https://ieeexplore.ieee.org/abstract/document/9503377">H.266/VVC</a>, 
          <a href="https://ieeexplore.ieee.org/abstract/document/6316136">H.265/HEVC</a>, 
          <a href="https://bellard.org/bpg/">BPG</a></span><br>
          <span style="color: rgba(89, 0, 255, 0.753);">Related End-to-End Image Codec: 
          <a href="https://arxiv.org/abs/1802.01436">Factorized Model</a>,
          <a href="https://arxiv.org/abs/1802.01436">Hyperprior Model</a>, 
          <a href="https://proceedings.neurips.cc/paper/2018/hash/53edebc543333dfbf7c5933af792c9c4-Abstract.html">Autoregressive Model</a>, 
          <a href="https://openaccess.thecvf.com/content_CVPR_2020/html/Cheng_Learned_Image_Compression_With_Discretized_Gaussian_Mixture_Likelihoods_and_Attention_CVPR_2020_paper.html">Cheng2020</a>, 
          <a href="https://ieeexplore.ieee.org/abstract/document/9204799">iWave++</a>,
          <a href="https://openaccess.thecvf.com/content/CVPR2022/html/He_ELIC_Efficient_Learned_Image_Compression_With_Unevenly_Grouped_Space-Channel_Contextual_CVPR_2022_paper.html">ELIC</a>, 
          <a href="https://dl.acm.org/doi/abs/10.1145/3581783.3611694">MLIC++</a></span><br>
          <span style="color: rgba(89, 0, 255, 0.753);">Related End-to-End Video Codec: 
          <a href="https://ieeexplore.ieee.org/abstract/document/9072487">DVC_Pro</a>, 
          <a href="https://proceedings.neurips.cc/paper_files/paper/2021/hash/96b250a90d3cf0868c83f8c965142d2a-Abstract.html">DCVC</a>, 
          <a href="https://link.springer.com/chapter/10.1007/978-3-031-19787-1_12">CANF-VC</a>, 
          <a href="https://ieeexplore.ieee.org/abstract/document/9941493">TCM-VC</a>, 
          <a href="https://dl.acm.org/doi/abs/10.1145/3503161.3547845">DCVC-HEM</a>, 
          <a href="https://ojs.aaai.org/index.php/AAAI/article/view/28317">OOFE</a>, 
          <a href="https://ieeexplore.ieee.org/abstract/document/10411051">VNVC</a>, 
          <a href="https://ieeexplore.ieee.org/abstract/document/10416688">SDD</a>, 
          <a href="https://openaccess.thecvf.com/content/CVPR2023/html/Li_Neural_Video_Compression_With_Diverse_Contexts_CVPR_2023_paper.html">DCVC-DC</a>, 
          <a href="https://openaccess.thecvf.com/content/CVPR2024/html/Li_Neural_Video_Compression_with_Feature_Modulation_CVPR_2024_paper.html">DCVC-FM</a></span><br>
          <span style="color: rgba(89, 0, 255, 0.753);">Related INR-based Video Codec: 
          <a href="https://proceedings.neurips.cc/paper/2021/hash/b44182379bf9fae976e6ae5996e13cd8-Abstract.html">NeRV</a>,
          <a href="https://openaccess.thecvf.com/content/CVPR2023/html/Chen_HNeRV_A_Hybrid_Neural_Representation_for_Videos_CVPR_2023_paper.html">HNerV</a>,
          <a href="https://proceedings.neurips.cc/paper_files/paper/2023/hash/e5dc475c370ff42f2f96dddf8191a40c-Abstract-Conference.html">HiNerV</a>,
          <a href="https://arxiv.org/abs/2409.07414">NVRC</span><br>
          [<a href="./files/USTC-TD/USTC-TD.pdf">PDF</a>] 
          [<a href="https://ieeexplore.ieee.org/abstract/document/11155177/">DOI</a>] 
          [<a href="./files/USTC-TD/sup.pdf">Supplementary</a>]
          [<a href="https://arxiv.org/abs/2409.08481">arXiv</a>]
          [<a href="https://esakak.github.io/USTC-TD/">Project Page</a>]
          [<a href="https://github.com/EsakaK/USTC-TD">Data</a>]
          [<a href="https://github.com/EsakaK/USTC-TD/tree/main/code">Code</a>]
        </td>
      </tr>

      <tr>
        <td style="line-height: 1.5;">
          <img src="./images/pic/LUT-ILF++-crop.png" width="200" height="100">
        </td>
        <td>
          <papertitle style="line-height: 1.5;"><a href="https://arxiv.org/abs/2509.09494">
          In-Loop Filtering Using Learned Look-Up Tables for Video Coding </a></papertitle> <br>
          <strong>Zhuoyuan Li</strong>, Jiacheng Li, Yao Li, Jialin Li, Li Li, Dong Liu*, and Feng Wu<br>
          <em> Arxiv Preprint</em>, 2025<br>
          <span style="color: rgba(89, 0, 255, 0.753);">Related Codec: 
          <a href="https://ieeexplore.ieee.org/abstract/document/9503377">H.266/VVC</a>, 
          Related Module: 
          <a href="https://ieeexplore.ieee.org/abstract/document/9399506">In-Loop Filtering</a></span><br>
          [<a href="./files/LUT-ILF++/LUT-ILF++.pdf">PDF</a>]
          [<a href="https://arxiv.org/abs/2509.09494">arXiv</a>]
        </td>
      </tr>

      <tr>
        <td style="line-height: 1.5;">
          <img src="./images/pic/UAMM-crop.png" width="200" height="45">
        </td>
        <td>
          <papertitle style="line-height: 1.5;"><a href="https://ieeexplore.ieee.org/abstract/document/10849917">
          Uniformly Accelerated Motion Model for Inter Prediction</a></papertitle> <br>
          <strong>Zhuoyuan Li</strong>, Yao Li, Chuanbo Tang, Li Li, Dong Liu, and Feng Wu*<br>
          <em> IEEE International Conference on Visual Communications and Image Processing</em> (VCIP), Poster, 2024<br>
          <span style="color: rgba(89, 0, 255, 0.753);">Related Codec: 
          <a href="https://ieeexplore.ieee.org/abstract/document/9503377">H.266/VVC</a>, 
          Related Module: 
          <a href="https://ieeexplore.ieee.org/abstract/document/9502124">Inter Prediction</a></span><br>
          [<a href="./files/UAMM/20241008_UAMM_vcip2024_camera_v2.pdf">PDF</a>] 
          [<a href="https://ieeexplore.ieee.org/abstract/document/10849917">DOI</a>] 
          [<a href="https://arxiv.org/abs/2407.11541v2">arXiv</a>]
          [<a href="./files/UAMM/20241008_UAMM_vcip2024_poster.pdf">VCIP2024 Poster</a>]
        </td>
      </tr>

      <tr>
        <td style="line-height: 1.5;">
          <img src="./images/pic/LUT-ILF-crop.png" width="200" height="90">
        </td>
        <td>
          <papertitle style="line-height: 1.5;"><a href="https://ieeexplore.ieee.org/abstract/document/10849824">
          In-Loop Filtering via Trained Look-Up Tables</a></papertitle> <br>
          <strong>Zhuoyuan Li</strong>, Jiacheng Li, Yao Li, Li Li, Dong Liu*, and Feng Wu<br>
          <em> IEEE International Conference on Visual Communications and Image Processing</em> (VCIP), Oral, 2024<br>
          <span style="color: rgba(89, 0, 255, 0.753);">Related Codec: 
          <a href="https://ieeexplore.ieee.org/abstract/document/9503377">H.266/VVC</a>, 
          Related Module: 
          <a href="https://ieeexplore.ieee.org/abstract/document/9399506">In-Loop Filtering</a></span><br>
          [<a href="./files/LUT-ILF/20241008_LUT-ILF_vcip2024_camera_v2.pdf">PDF</a>]
          [<a href="https://ieeexplore.ieee.org/abstract/document/10849824">DOI</a>] 
          [<a href="https://arxiv.org/abs/2407.10926v2">arXiv</a>]
          [<a href="./files/LUT-ILF/20241201_LUT-ILF_oral_presentation.pdf">VCIP2024 Presentation</a>]
        </td>
      </tr>

      <tr>
        <td style="line-height: 1.5;">
          <img src="./images/pic/Inter-phd.png" width="200" height="30">
        </td>
        <td>
          <papertitle style="line-height: 1.5;"><a href="https://vcip2025.itec.aau.at/call-for-doctoral-symposium/">
          Inter Prediction in the Era of Emerging Traditional and Learned Video Compression</a></papertitle> <br>
          <strong>Zhuoyuan Li</strong><br>
          <em> IEEE International Conference on Visual Communications and Image Processing</em> (VCIP), Oral, 2025<br>
          <span style="color: rgba(89, 0, 255, 0.753);">Related Codec: 
          <a href="https://ieeexplore.ieee.org/abstract/document/9503377">H.266/VVC</a>, 
          <a href="https://proceedings.neurips.cc/paper_files/paper/2021/hash/96b250a90d3cf0868c83f8c965142d2a-Abstract.html">DCVC</a>, 
          <a href="https://openaccess.thecvf.com/content/CVPR2023/html/Li_Neural_Video_Compression_With_Diverse_Contexts_CVPR_2023_paper.html">DCVC-DC</a>, 
          <a href="https://openaccess.thecvf.com/content/CVPR2024/html/Li_Neural_Video_Compression_with_Feature_Modulation_CVPR_2024_paper.html">DCVC-FM</a>,
          <a href="https://ieeexplore.ieee.org/abstract/document/9443088">JPEG XS</a></span><br>
          <span style="color: rgba(89, 0, 255, 0.753);">Related Module: 
          <a href="https://ieeexplore.ieee.org/abstract/document/9502124">Inter Prediction</a>,
          <a href="https://ieeexplore.ieee.org/abstract/document/9452121">Partition</a>,
          <a href="https://ieeexplore.ieee.org/abstract/document/9399506">In-Loop Filtering</a></span><br>
          [<a href="https://vcip2025.itec.aau.at/call-for-doctoral-symposium/">PDF</a>]
          [<a href="https://vcip2025.itec.aau.at/call-for-doctoral-symposium/">DOI</a>] 
        </td>
      </tr>

      <tr>
        <td style="line-height: 1.5;">
          <img src="./images/pic/IPC.png" width="200" height="80">
        </td>
        <td>
          <papertitle style="line-height: 1;"><a href="https://ieeexplore.ieee.org/document/10972021">
          Frequency Domain Intra Pattern Copy for JPEG XS Screen Content Coding</a></papertitle> <br>
          Yao Li, <strong>Zhuoyuan Li</strong>, Dong Liu, and Li Li*<br>
          <em> IEEE Transactions on Circuits and Systems for Video Technology </em> (TCSVT), 2025<br>
          <span style="color: rgba(89, 0, 255, 0.753);">Related Codec: 
          <a href="https://ieeexplore.ieee.org/abstract/document/9443088">JPEG XS</a>, 
          Related Module: <a href="https://ieeexplore.ieee.org/abstract/document/7547947">Intra Prediction</span><br>
          [<a href="./files/F-IPC/F-IPC.pdf">PDF</a>] 
          [<a href="https://ieeexplore.ieee.org/document/10972021">DOI</a>] 
        </td>
      </tr>

      <tr>
        <td style="line-height: 1.5;">
          <img src="./images/pic/PMPI.png" width="200" height="100">
        </td>
        <td>
          <papertitle style="line-height: 1;"><a href="https://arxiv.org/abs/2504.18398">
          Partition Map-Based Fast Block Partitioning for VVC Inter Coding</a></papertitle> <br>
          Xinmin Feng, <strong>Zhuoyuan Li</strong>, Li Li, Dong Liu*, and Feng Wu<br>
          <em>IEEE Transactions on Multimedia</em> (TMM), 2025 <br>
          <span style="color: rgba(89, 0, 255, 0.753);">Related Codec: 
          <a href="https://ieeexplore.ieee.org/abstract/document/9503377">H.266/VVC</a>, 
          Related Module: <a href="https://ieeexplore.ieee.org/abstract/document/9452121">Partition</span><br>
          [<a href="https://arxiv.org/abs/2504.18398">PDF</a>] 
          [<a href="https://arxiv.org/abs/2504.18398">DOI</a>] 
          [<a href="https://arxiv.org/abs/2504.18398">arXiv</a>]
          [<a href="https://github.com/ustc-ivclab/IPM">Code</a>]
        </td>
      </tr>

      <tr>
        <td style="line-height: 1.5;">
          <img src="./images/pic/DCVC-CM.png" width="200" height="120">
        </td>
        <td>
          <papertitle style="line-height: 1.5;"><a href="https://openaccess.thecvf.com/content/CVPR2025/html/Tang_Neural_Video_Compression_with_Context_Modulation_CVPR_2025_paper.html">
          Neural Video Compression with Context Modulation</a></papertitle> <br>
          Chuanbo Tang, <strong>Zhuoyuan Li</strong>, Yifan Bian, Li Li, and Dong Liu*<br>
          <em> Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em> (CVPR), 2025 <br>
          <span style="color: rgba(255, 0, 0, 0.904);">Vision And Learning SEminar (VALSE 2025) Poster Presentation</span><br>
          <span style="color: rgba(89, 0, 255, 0.753);">Related Codec: 
          <a href="https://proceedings.neurips.cc/paper_files/paper/2021/hash/96b250a90d3cf0868c83f8c965142d2a-Abstract.html">DCVC</a>,
          <a href="https://ieeexplore.ieee.org/abstract/document/9941493">TCM-VC</a>, 
          <a href="https://dl.acm.org/doi/abs/10.1145/3503161.3547845">DCVC-HEM</a>, 
          <a href="https://openaccess.thecvf.com/content/CVPR2023/html/Li_Neural_Video_Compression_With_Diverse_Contexts_CVPR_2023_paper.html">DCVC-DC</a>, 
          <a href="https://openaccess.thecvf.com/content/CVPR2024/html/Li_Neural_Video_Compression_with_Feature_Modulation_CVPR_2024_paper.html">DCVC-FM</a>,
          Related Module: 
          <a href="https://ieeexplore.ieee.org/abstract/document/8456249">Inter Prediction</a></span><br>
          [<a href="./files/DCVC-CM/DCVC-CM.pdf">PDF</a>]
          [<a href="https://arxiv.org/abs/2505.14541">arXiv</a>]
          [<a href="https://openaccess.thecvf.com/content/CVPR2025/html/Tang_Neural_Video_Compression_with_Context_Modulation_CVPR_2025_paper.html">DOI</a>]
          [<a href="./files/DCVC-CM/Poster_DCMVC.pdf">Poster</a>]  
          [<a href="./files/DCVC-CM/Valse_DCMVC.pdf">VALSE2025 Poster</a>]  
        </td>
      </tr>

      <tr>
        <td style="line-height: 1.5;">
          <img src="./images/pic/DCVC-RH.png" width="200" height="120">
        </td>
        <td>
          <papertitle style="line-height: 1.5;"><a href="https://openaccess.thecvf.com/content/CVPR2025/html/Tang_Neural_Video_Compression_with_Context_Modulation_CVPR_2025_paper.html">
          Neural Video Compression with Reference Hierarchy</a></papertitle> <br>
          Chuanbo Tang, <strong>Zhuoyuan Li</strong>, Li Li, Dong Liu*, and Feng Wu<br>
          <em> Proceedings of the AAAI Conference on Artificial Intelligence</em> (AAAI), Poster, 2026 <br>
          <span style="color: rgba(89, 0, 255, 0.753);">Related Codec: 
          <a href="https://proceedings.neurips.cc/paper_files/paper/2021/hash/96b250a90d3cf0868c83f8c965142d2a-Abstract.html">DCVC</a>,
          <a href="https://ieeexplore.ieee.org/abstract/document/9941493">TCM-VC</a>, 
          <a href="https://dl.acm.org/doi/abs/10.1145/3503161.3547845">DCVC-HEM</a>, 
          <a href="https://openaccess.thecvf.com/content/CVPR2023/html/Li_Neural_Video_Compression_With_Diverse_Contexts_CVPR_2023_paper.html">DCVC-DC</a>, 
          <a href="https://openaccess.thecvf.com/content/CVPR2024/html/Li_Neural_Video_Compression_with_Feature_Modulation_CVPR_2024_paper.html">DCVC-FM</a>,
          Related Module: 
          <a href="https://ieeexplore.ieee.org/abstract/document/8456249">Inter Prediction</a></span><br>
          [<a href="./images/pic/DCVC-RH.png">PDF</a>]
          [<a href="./images/pic/DCVC-RH.png">arXiv</a>]
          [<a href="./images/pic/DCVC-RH.png">DOI</a>]
          [<a href="./images/pic/DCVC-RH.png">Poster</a>]  
        </td>
      </tr>

      <tr>
        <td style="line-height: 1.5;">
          <img src="./images/pic/CDMVR-crop.png" width="200" height="60">
        </td>
        <td>
          <papertitle style="line-height: 1.5;"><a href="https://ieeexplore.ieee.org/abstract/document/11043848">
          Collaborative Decoder-side Motion Vector Refinement for Video Coding</a></papertitle> <br>
          Jialin Li, <strong>Zhuoyuan Li</strong>, Yao Li, Li Li*, and Houqiang Li<br>
          <em> IEEE International Symposium on Circuits and Systems</em> (ISCAS), Poster, 2025 <br>
          <span style="color: rgba(89, 0, 255, 0.753);">Related Codec: 
          <a href="https://ieeexplore.ieee.org/abstract/document/9428244">AOMedia Video 2 (AV2)</a>, 
          Related Module: 
          <a href="https://ieeexplore.ieee.org/abstract/document/8456249">Inter Prediction</a></span><br>
          [<a href="./files/CDMVR/Collaborative_Decoder-side_Motion_Vector_Refinement_for_Video_Coding.pdf">PDF</a>]
          [<a href="./files/CDMVR/CDMVR-poster.pdf">Poster</a>] 
          [<a href="https://ieeexplore.ieee.org/abstract/document/11043848">DOI</a>]
        </td>
      </tr>

      <tr>
        <td style="line-height: 1.5;">
          <img src="./images/pic/GHMC-crop.png" width="200" height="100">
        </td>
        <td>
          <papertitle style="line-height: 1.5;"><a href="https://ieeexplore.ieee.org/abstract/document/10008901">
          Global Homography Motion Compensation for Versatile Video Coding</a></papertitle> <br>
          Yao Li, <strong>Zhuoyuan Li</strong>, Li Li*, Dong Liu, and Houqiang Li<br>
          <em> IEEE International Conference on Visual Communications and Image Processing</em> (VCIP), Oral, 2022 <br>
          <span style="color: rgba(89, 0, 255, 0.753);">Related Codec: 
          <a href="https://ieeexplore.ieee.org/abstract/document/9503377">H.266/VVC</a>, 
          Related Module: 
          <a href="https://ieeexplore.ieee.org/abstract/document/9502124">Inter Prediction</a></span><br>
          [<a href="./files/GHMC/GHMC.pdf">PDF</a>]
          [<a href="https://ieeexplore.ieee.org/abstract/document/10008901">DOI</a>]
        </td>
      </tr>

      <tr>
        <td style="line-height: 1.5;">
          <img src="./images/pic/RJOVC-crop.png" width="200" height="60">
        </td>
        <td>
          <papertitle style="line-height: 1.5;"><a href="https://ieeexplore.ieee.org/abstract/document/10533815">
          Rethinking the Joint Optimization in Video Coding for Machines: A Case Study</a></papertitle> <br>
          Changsheng Gao, <strong>Zhuoyuan Li</strong>, Li Li, Dong Liu*, and Feng Wu <br>
          <em> Data Compression Conference </em> (DCC), Poster, 2024 <br>
          <span style="color: rgba(89, 0, 255, 0.753);">Related Codec: 
          <a href="https://ieeexplore.ieee.org/abstract/document/8848858/">Feature Compression</a>, 
          Related Module: 
          <a href="https://ieeexplore.ieee.org/abstract/document/10533815">Joint Optimization</a></span><br>
          [<a href="./files/RJOVC/RJOVC.pdf">PDF</a>] 
          [<a href="https://ieeexplore.ieee.org/abstract/document/10533815">DOI</a>] 
          [<a href="./files/RJOVC/RJOVC-poster.pdf">DCC2024 Poster</a>] 
        </td>
      </tr>

      <tr>
        <td style="line-height: 1.5;">
          <img src="./images/pic/RJOFC-crop.png" width="200" height="60">
        </td>
        <td>
          <papertitle style="line-height: 1.5;"><a href="https://ieeexplore.ieee.org/abstract/document/10533815">
          Rethinking Joint Optimization in Feature Compression: Insights from Person Re-Identification</a></papertitle> <br>
          Changsheng Gao, <strong>Zhuoyuan Li</strong>, Li Li, Dong Liu, Feng Wu, and Weisi Lin <br>
          <em> IEEE International Conference on Multimedia & Expo </em> (ICME), 2025 <br>
          <span style="color: rgba(89, 0, 255, 0.753);">Related Codec: 
          <a href="https://ieeexplore.ieee.org/abstract/document/8848858/">Feature Compression</a>, 
          Related Module: 
          <a href="https://ieeexplore.ieee.org/abstract/document/10533815">Joint Optimization</a></span><br>
          [<a href="./images/pic/RJOFC-crop.png">PDF</a>] 
          [<a href="./images/pic/RJOFC-crop.png">DOI</a>] 
        </td>
      </tr>

      <tr>
        <td style="line-height: 1.5;">
          <img src="./images/pic/DME.png" width="200" height="90">
        </td>
        <td>
          <papertitle style="line-height: 1.5;"><a href="https://ZhuoyuanLi1997.github.io">
          Learning Dual Modality Interactions for Event-based Motion Deblurring</a></papertitle> <br>
          Zeyu Xiao, <strong>Zhuoyuan Li</strong>, Yang Zhao, Yu Liu, Zhao Zhang and Wei Jia*<br>
          <em> IEEE Transactions on Multimedia</em> (TMM), 2025 <br>
          <span style="color: rgba(89, 0, 255, 0.753);">
          Related Area: 
          <a href="https://ieeexplore.ieee.org/abstract/document/9138762/">Event Camera</a>,
          Related Module:
          <a href="https://link.springer.com/article/10.1007/s10462-022-10147-y">Video Super-Resolution</a>
          </span><br>
          [<a href="https://ZhuoyuanLi1997.github.io">PDF</a>]
          [<a href="https://ZhuoyuanLi1997.github.io">DOI</a>]
        </td>
      </tr>

      <tr>
        <td style="line-height: 1.5;">
          <img src="./images/pic/OHT.png" width="200" height="60">
        </td>
        <td>
          <papertitle style="line-height: 1.5;"><a href="https://ojs.aaai.org/index.php/AAAI/article/view/32940">
          Occlusion-Embedded Hybrid Transformer for Light Field Super-Resolution</a></papertitle> <br>
          Zeyu Xiao, <strong>Zhuoyuan Li</strong>, and Wei Jia*<br>
          <em> Proceedings of the AAAI Conference on Artificial Intelligence</em> (AAAI), Poster, 2025 <br>
          <span style="color: rgba(89, 0, 255, 0.753);">
          Related Area: 
          <a href="https://www.cv-foundation.org/openaccess/content_iccv_2015_workshops/w3/papers/Yoon_Learning_a_Deep_ICCV_2015_paper.pdf">Light Field Image Super-Resolution</a>,
          Related Module:
          <a href="https://ieeexplore.ieee.org/abstract/document/9716741">Vision Transformer</a>
          </span><br>
          [<a href="./files/OHT/OHT-AAAI.pdf">PDF</a>]
          [<a href="https://ojs.aaai.org/index.php/AAAI/article/view/32940">DOI</a>]
        </td>
      </tr>

      <tr>
        <td style="line-height: 1.5;">
          <img src="./images/pic/TWT-crop.png" width="200" height="85">
        </td>
        <td>
          <papertitle style="line-height: 1;"><a href="https://ieeexplore.ieee.org/abstract/document/10254565">
          Temporal Wavelet Transform-Based Low-Complexity Perceptual Quality Enhancement of Compressed Video</a></papertitle> <br>
          Cunhui Dong, Haichuan Ma (Co-first), <strong>Zhuoyuan Li</strong>, Li Li, and Dong Liu*<br>
          <em> IEEE Transactions on Circuits and Systems for Video Technology </em> (TCSVT), 2024<br>
          <span style="color: rgba(255, 0, 0, 0.904);">Chinese Congress on Image and Graphics (CCIG 2024) Spotlight Presentation</span><br>
          <span style="color: rgba(89, 0, 255, 0.753);">Related Codec: 
          <a href="https://ieeexplore.ieee.org/abstract/document/9503377">H.266/VVC</a>, 
          <a href="https://ieeexplore.ieee.org/abstract/document/6316136">H.265/HEVC</a>, 
          Related Module: <a href="https://ieeexplore.ieee.org/abstract/document/9399506">Post-Processing</span><br>
          [<a href="./files/TWT/TWT.pdf">PDF</a>] 
          [<a href="https://ieeexplore.ieee.org/abstract/document/10254565">DOI</a>] 
          [<a href="./files/TWT/TWT-poster.pdf">CCIG2024 Poster</a>] 
        </td>
      </tr>

      <tr>
        <td style="line-height: 1.5;">
          <img src="./images/pic/IVCA-crop.png" width="200" height="80">
        </td>
        <td>
          <papertitle style="line-height: 1.5;"><a href="https://ieeexplore.ieee.org/abstract/document/11044286">
          IVCA: Inter-Relation-Aware Video Complexity Analyzer</a></papertitle> <br>
          Junqi Liao, Yao Li (Co-first), <strong>Zhuoyuan Li</strong>, Li Li*, and Dong Liu<br>
          <em> IEEE International Symposium on Circuits and Systems</em> (ISCAS), Oral, 2025 <br>
          <span style="color: rgba(255, 0, 0, 0.904);">Project Report for ICIP 2024 Grand Challenge on Video Complexity, <br>Wining Team (USTC-iVC1) and 1st Runner-up Team (USTC-iVC2)</span><br>
          <span style="color: rgba(89, 0, 255, 0.753);">Related Codec: 
          <a href="https://dl.acm.org/doi/abs/10.1145/3524273.3532896">Video Complexity Analyzer (VCA)</a>, 
          Related Module: <a href="https://ieeexplore.ieee.org/abstract/document/9502124">Inter Prediction</span><br>
          [<a href="./files/IVCA/IVCA_ISCAS2025.pdf">PDF</a>] 
          [<a href="./files/IVCA/IVCA_challenge_report.pdf">Challenge Report</a>] 
          [<a href="https://arxiv.org/abs/2407.00280">arXiv</a>] 
          [<a href="https://ieeexplore.ieee.org/abstract/document/11044286">DOI</a>] 
        </td>
      </tr>

      <tr>
        <td style="line-height: 1.5;">
          <img src="./images/pic/OOFE-crop.png" width="200" height="110">
        </td>
        <td>
          <papertitle style="line-height: 1.5;"><a href="https://ojs.aaai.org/index.php/AAAI/article/view/28317">
          Offline and Online Optical Flow Enhancement for Deep Video Compression</a></papertitle> <br>
          Chuanbo Tang, Xihua Sheng, <strong>Zhuoyuan Li</strong>, Haotian Zhang, Li Li, and Dong Liu*<br>
          <em> Proceedings of the AAAI Conference on Artificial Intelligence </em> (AAAI), Poster, 2024 <br>
          <span style="color: rgba(255, 0, 0, 0.904);">Vision And Learning SEminar (VALSE 2024) Poster Presentation</span><br>
          <span style="color: rgba(89, 0, 255, 0.753);">Related Codec: 
          <a href="https://proceedings.neurips.cc/paper_files/paper/2021/hash/96b250a90d3cf0868c83f8c965142d2a-Abstract.html">DCVC</a>,
          <a href="https://ieeexplore.ieee.org/abstract/document/9941493">TCM-VC</a>, 
          <a href="https://dl.acm.org/doi/abs/10.1145/3503161.3547845">DCVC-HEM</a>, 
          <a href="https://openaccess.thecvf.com/content/CVPR2023/html/Li_Neural_Video_Compression_With_Diverse_Contexts_CVPR_2023_paper.html">DCVC-DC</a>, 
          Related Module: <a href="https://ieeexplore.ieee.org/abstract/document/9502124">Inter Prediction</span><br>
          [<a href="./files/OOFE/OOFE.pdf">PDF</a>] 
          [<a href="https://ojs.aaai.org/index.php/AAAI/article/view/28317">DOI</a>] 
          [<a href="./files/OOFE/AAAI-PPT.pdf">PPT</a>]
          [<a href="./files/OOFE/AAAI-poster.pdf">Poster</a>]
          [<a href="./files/OOFE/AAAI-valse.pdf">VALSE2024 Poster</a>]  
          [<a href="https://arxiv.org/abs/2307.05092">arXiv</a>] 
        </td>
      </tr>
    </tbody></table>

    <a id="Honors" class="anchor"></a><span class="section">Honors and Awards</a> </span>
    <table border="0" width="95%" class="paper" style="border-collapse:separate; border-spacing:10px;">
      <tbody>
        <tr>
          <td style="line-height: 1.5;">
            <img src="./images/pic/prcv2025.png" width="200" height="70">
          </td>
          <td>
            <papertitle style="line-height: 1.5;"><a href="https://www.prcv.cn/Competitions4/">
            Grand Challenge on "SpikeCV"</a></papertitle><br>
            <em> Chinese Conference on Pattern Recognition and Computer Vision</em> (PRCV), 2025<br>
            <span style="color: rgba(255, 0, 0, 0.904);"><strong>Outstanding Exploration Award</strong></span>,<br>
            Research Topic: Towards Next-Generation Spike Data Compression<br>
            <strong>Zhuoyuan Li</strong><br>
            Advisor: Cong Zhang<br>
            [<a href="./files/PRCV2025/SpikeCV.pdf">PDF</a>]
            [<a href="https://www.prcv.cn/Competitions4/">LINK</a>]
          </td>
        </tr>

        <tr>
          <td style="line-height: 1.5;">
            <img src="./images/pic/VCIP2025.png" width="200" height="110">
          </td>
          <td>
            <papertitle style="line-height: 1.5;"><a href="https://www.mc-if.org/vcip-grand-challenge-decoder-complexity-aware-encoding-with-vvc-h-266/">
            Grand Challenge on "Decoder Complexity-Aware Encoding Challenge with VVC/H.266"</a></papertitle><br>
            <em> IEEE International Conference on Visual Communications and Image Processing</em> (VCIP), 2025<br>
            <span style="color: rgba(255, 0, 0, 0.904);"><strong>Winner Prize</strong></span>,
            Team: USTC-iVC<br>
            Jialin Li, Mingming Zhang, Jiazhen Wang, Yao Li, Xinmin Feng, Haotian Zhang, Junqi Liao, Yuqi Li, Chuanbo Tang, <strong>Zhuoyuan Li</strong><br>
            Advisor: Li Li, Dong Liu<br>
            [<a href="">PDF</a>]
            [<a href="https://www.mc-if.org/vcip-grand-challenge-decoder-complexity-aware-encoding-with-vvc-h-266/">LINK</a>]
          </td>
        </tr>

        <tr>
          <td style="line-height: 1.5;">
            <img src="./images/pic/NeurIPS.png" width="200" height="90">
          </td>
          <td>
            <papertitle style="line-height: 1.5;"><a href="https://neurips.cc/">
            NeurIPS 2025 Top Reviewer</a></papertitle><br>
            <em> Thirty-Ninth Annual Conference on Neural Information Processing Systems</em> (NeurIPS), 2025<br>
            [<a href="https://neurips.cc/">PDF</a>]
          </td>
        </tr>

        <tr>
          <td style="line-height: 1.5;">
            <img src="./images/pic/ICIP.png" width="200" height="110">
          </td>
          <td>
            <papertitle style="line-height: 1.5;"><a href="https://2024.ieeeicip.org/challenges/">
            Grand Challenge on "Video Complexity"</a></papertitle><br>
            <em> IEEE International Conference on Image Processing</em> (ICIP), 2024<br>
            <span style="color: rgba(255, 0, 0, 0.904);"><strong>Winner Prize</strong></span>,
            Team: USTC-iVC1<br>
            Junqi Liao, Yao Li, <strong>Zhuoyuan Li</strong><br>
            Advisor: Li Li, Dong Liu<br>
            [<a href="./files/IVCA/Certificates_Grand-challenge-Award_ICIP24.pdf">PDF</a>]
            [<a href="https://2024.ieeeicip.org/challenges/">LINK</a>]
          </td>
        </tr>

        <tr>
          <td style="line-height: 1.5;">
            <img src="./images/pic/ICIP.png" width="200" height="110">
          </td>
          <td>
            <papertitle style="line-height: 1.5;"><a href="https://2024.ieeeicip.org/challenges/">
            Grand Challenge on "Video Complexity"</a></papertitle> <br>
            <em> IEEE International Conference on Image Processing</em> (ICIP), 2024<br>
            <span style="color: rgba(255, 0, 0, 0.904);"><strong>1st Runner-up Prize</strong></span>,
            Team: USTC-iVC2<br>
            Yao Li, Junqi Liao, <strong>Zhuoyuan Li</strong><br>
            Advisor: Li Li, Dong Liu<br>
            [<a href="./files/IVCA/Certificates_Grand-challenge-Award_ICIP24.pdf">PDF</a>]
            [<a href="https://2024.ieeeicip.org/challenges/">LINK</a>]
          </td>
        </tr>

        <tr>
          <td style="line-height: 1.5;">
            <img src="./images/pic/VCIP.png" width="200" height="100">
          </td>
          <td>
            <papertitle style="line-height: 1.5;"><a href="https://vcip2023.iforum.biz/page/goto/">
            Grand Challenge on "End-to-End Practical Video Compression"</a></papertitle> <br>
            <em> IEEE International Conference on Visual Communications and Image Processing</em> (VCIP), 2023<br>
            <span style="color: rgba(255, 0, 0, 0.904);"><strong>1st Runner-up Prize</strong></span>, Team: BOotingFANtasticalLY<br>
            Yifan Bian, Chuanbo Tang, Yao Li, <strong>Zhuoyuan Li</strong><br>
            Advisor: Li Li, Dong Liu<br>
            [<a href="./files/VCIP_Challenge/Certificates_Grand-challenge-Award_VCIP23.pdf">PDF</a>]
            [<a href="https://vcip2023.iforum.biz/page/goto/">LINK</a>]
          </td>
        </tr>
        
        <tr>
          <td style="line-height: 1.5;">
            <img src="./images/pic/MMSP.png" width="200" height="100">
          </td>
          <td>
            <papertitle style="line-height: 1.5;"><a href="https://attend.ieee.org/mmsp-2024/">
            Grand Challenge on "End-to-End Practical Image Compression"</a></papertitle> <br>
            <em> International Workshop on Multimedia Signal Processing</em> (MMSP), 2024<br>
            <span style="color: rgba(255, 0, 0, 0.904);"><strong>Winner Prize</strong> (Performance Track)</span>, Team: USTC-iVC<br>
            Yuqi Li, Haotian Zhang, Yifan Bian, Chuanbo Tang, Changsheng Gao, <strong>Zhuoyuan Li</strong><br>
            Advisor: Li Li, Dong Liu<br>
            [<a href="./files/MMSP_Challenge/2024-MMSP-challenge_winner_1.pdf">PDF</a>]
            [<a href="https://faculty.ustc.edu.cn/lil1/en/zdylm/991871/list/index.htm">LINK</a>]
          </td>
        </tr> 

        <tr>
          <td style="line-height: 1.5;">
            <img src="./images/pic/MMSP.png" width="200" height="100">
          </td>
          <td>
            <papertitle style="line-height: 1.5;"><a href="https://attend.ieee.org/mmsp-2024/">
            Grand Challenge on "End-to-End Practical Image Compression"</a></papertitle> <br>
            <em> International Workshop on Multimedia Signal Processing</em> (MMSP), 2024<br>
            <span style="color: rgba(255, 0, 0, 0.904);"><strong>Winner Prize</strong> (Complexity Track)</span>, Team: USTC-iVC<br>
            Yuqi Li, Haotian Zhang, Yifan Bian, Chuanbo Tang, Changsheng Gao, <strong>Zhuoyuan Li</strong><br>
            Advisor: Li Li, Dong Liu<br>
            [<a href="./files/MMSP_Challenge/2024-MMSP-challenge_winner_2.pdf">PDF</a>]
            [<a href="https://faculty.ustc.edu.cn/lil1/en/zdylm/991871/list/index.htm">LINK</a>]
          </td>
        </tr> 
 
        <tr>
          <td style="line-height: 1.5;">
            <img src="./images/pic/MMSP.png" width="200" height="100">
          </td>
          <td>
            <papertitle style="line-height: 1.5;"><a href="https://attend.ieee.org/mmsp-2024/">
            Grand Challenge on "End-to-End Practical Video Compression"</a></papertitle> <br>
            <em> International Workshop on Multimedia Signal Processing</em> (MMSP), 2024<br>
            <span style="color: rgba(255, 0, 0, 0.904);"><strong>Winner Prize</strong> (Performance Track)</span>, Team: USTC-iVC<br>
            Yifan Bian, Chuanbo Tang, Yuqi Li, Haotian Zhang, Changsheng Gao, <strong>Zhuoyuan Li</strong><br>
            Advisor: Li Li, Dong Liu<br>
            [<a href="./files/MMSP_Challenge/2024-MMSP-challenge_winner_4.pdf">PDF</a>]
            [<a href="https://faculty.ustc.edu.cn/lil1/en/zdylm/991871/list/index.htm">LINK</a>]
          </td>
        </tr>

        <tr>
          <td style="line-height: 1.5;">
            <img src="./images/pic/NTIRE2025.png" width="200" height="70">
          </td>
          <td>
            <papertitle style="line-height: 1.5;"><a href="https://www.cvlai.net/ntire/2025/">
            NTIRE 2025 challenge on Single Image Reflection Removal in the Wild</a></papertitle> <br>
            <em> Proceedings of the Computer Vision and Pattern Recognition Conference Workshop</em> (CVPRW), 2025<br>
            <span style="color: rgba(255, 0, 0, 0.904);"><strong>11th</strong></span>, Team: X-L<br>
            Zeyu Xiao, <strong>Zhuoyuan Li</strong><br>
            [<a href="./files/NTIRE2025/Yang_NTIRE_2025_Challenge_on_Single_Image_Reflection_Removal_in_the_CVPRW_2025_paper.pdf">PDF</a>]
            [<a href=https://openaccess.thecvf.com/content/CVPR2025W/NTIRE/html/Yang_NTIRE_2025_Challenge_on_Single_Image_Reflection_Removal_in_the_CVPRW_2025_paper.html">LINK</a>]
          </td>
        </tr>

        <tr>
          <td style="line-height: 1.5;">
            <img src="./images/pic/NTIRE2025.png" width="200" height="70">
          </td>
          <td>
            <papertitle style="line-height: 1.5;"><a href="https://www.cvlai.net/ntire/2025/">
            NTIRE 2025 Challenge on Day and Night Raindrop Removal for Dual-Focused Images</a></papertitle> <br>
            <em> Proceedings of the Computer Vision and Pattern Recognition Conference Workshop</em> (CVPRW), 2025<br>
            <span style="color: rgba(255, 0, 0, 0.904);"><strong>25th</strong></span>, Team: X-L<br>
            Zeyu Xiao, <strong>Zhuoyuan Li</strong><br>
            [<a href="./files/NTIRE2025/Li_NTIRE_2025_Challenge_on_Day_and_Night_Raindrop_Removal_for_CVPRW_2025_paper.pdf">PDF</a>]
            [<a href=https://openaccess.thecvf.com/content/CVPR2025W/NTIRE/html/Li_NTIRE_2025_Challenge_on_Day_and_Night_Raindrop_Removal_for_CVPRW_2025_paper.html">LINK</a>]
          </td>
        </tr>

        <tr>
          <td style="line-height: 1.5;">
            <img src="./images/pic/NTIRE2025.png" width="200" height="70">
          </td>
          <td>
            <papertitle style="line-height: 1.5;"><a href="https://www.cvlai.net/ntire/2025/">
            NTIRE 2025 Efficient Super-Resolution Challenge</a></papertitle> <br>
            <em> Proceedings of the Computer Vision and Pattern Recognition Conference Workshop</em> (CVPRW), 2025<br>
            <span style="color: rgba(255, 0, 0, 0.904);"><strong>37th</strong></span>, Team: X-L<br>
            Zeyu Xiao, <strong>Zhuoyuan Li</strong><br>
            [<a href="./files/NTIRE2025/Ren_The_Tenth_NTIRE_2025_Efficient_Super-Resolution_Challenge_Report_CVPRW_2025_paper.pdf">PDF</a>]
            [<a href="https://openaccess.thecvf.com/content/CVPR2025W/NTIRE/html/Ren_The_Tenth_NTIRE_2025_Efficient_Super-Resolution_Challenge_Report_CVPRW_2025_paper.html">LINK</a>]
          </td>
        </tr>

        <tr>
          <td style="line-height: 1.5;">
            <img src="./images/pic/NTIRE2025.png" width="200" height="70">
          </td>
          <td>
            <papertitle style="line-height: 1.5;"><a href="https://www.cvlai.net/ntire/2025/">
            NTIRE 2025 Challenge on Efficient Burst HDR and Restoration</a></papertitle> <br>
            <em> Proceedings of the Computer Vision and Pattern Recognition Conference Workshop</em> (CVPRW), 2025<br>
            <span style="color: rgba(255, 0, 0, 0.904);"><strong>6nd</strong></span>, Team: X-L<br>
            Zeyu Xiao, <strong>Zhuoyuan Li</strong><br>
            [<a href="./files/NTIRE2025/Yang_NTIRE_2025_Challenge_on_Single_Image_Reflection_Removal_in_the_CVPRW_2025_paper.pdf">PDF</a>]
            [<a href=https://openaccess.thecvf.com/content/CVPR2025W/NTIRE/html/Lee_NTIRE_2025_Challenge_on_Efficient_Burst_HDR_and_Restoration_Datasets_CVPRW_2025_paper.html">LINK</a>]
          </td>
        </tr>

        <tr>
          <td style="line-height: 1.5;">
            <img src="./images/pic/NTIRE2025.png" width="200" height="70">
          </td>
          <td>
            <papertitle style="line-height: 1.5;"><a href="https://www.cvlai.net/ntire/2025/">
            NTIRE 2025 Challenge on Image Super-Resolution (×4)</a></papertitle> <br>
            <em> Proceedings of the Computer Vision and Pattern Recognition Conference Workshop</em> (CVPRW), 2025<br>
            <span style="color: rgba(255, 0, 0, 0.904);"><strong>5nd</strong></span>, Team: X-L<br>
            Zeyu Xiao, <strong>Zhuoyuan Li</strong><br>
            [<a href="./files/NTIRE2025/NTIRE 2025 Challenge on Image Super-Resolution (×4) Methods and Results.pdf">PDF</a>]
            [<a href=https://arxiv.org/pdf/2504.14582">LINK</a>]
          </td>
        </tr>

        <tr>
          <td style="line-height: 1.5;">
            <img src="./images/pic/NTIRE2025.png" width="200" height="70">
          </td>
          <td>
            <papertitle style="line-height: 1.5;"><a href="https://www.cvlai.net/ntire/2025/">
            NTIRE 2025 Image Denoising Challenge</a></papertitle> <br>
            <em> Proceedings of the Computer Vision and Pattern Recognition Conference Workshop</em> (CVPRW), 2025<br>
            <span style="color: rgba(255, 0, 0, 0.904);"><strong>18th</strong></span>, Team: X-L<br>
            Zeyu Xiao, <strong>Zhuoyuan Li</strong><br>
            [<a href="./files/NTIRE2025/Sun_The_Tenth_NTIRE_2025_Image_Denoising_Challenge_Report_CVPRW_2025_paper.pdf">PDF</a>]
            [<a href=https://openaccess.thecvf.com/content/CVPR2025W/NTIRE/html/Sun_The_Tenth_NTIRE_2025_Image_Denoising_Challenge_Report_CVPRW_2025_paper.html">LINK</a>]
          </td>
        </tr>

        <tr>
          <td style="line-height: 1.5;">
            <img src="./images/pic/SWJTU.png" width="200" height="140">
          </td>
          <td>
            <papertitle style="line-height: 1.5;"><a href="https://sist.swjtu.edu.cn/home?lang=cn">
            Undergraduate Thesis of Southwest Jiaotong University</a></papertitle> <br>
            <em> Southwest Jiaotong University</em> (SWJTU), 2018<br>
            <span style="color: rgba(255, 0, 0, 0.904);"><strong>Best Undergraduate Thesis, 1/93</span></strong><br> 
            Thesis Topic: Deep Learning-based Combined Intra and Inter Prediction for Versatile Video Coding<br>
            <strong>Zhuoyuan Li</strong><br>
            USTC Advisor: Dong Liu, Feng Wu<br>
            [<a href="./files/SWJTU_Thesis/Undergraduate_Thesis.jpg">PDF</a>]
            [<a href="https://sist.swjtu.edu.cn/home?lang=cn">LINK</a>]
          </td>
        </tr>

        <tr>
          <td style="line-height: 1.5;">
            <img src="./images/pic/CUMCM.png" width="200" height="150">
          </td>
          <td>
            <papertitle style="line-height: 1.5;"><a href="https://www.mcm.edu.cn/">
            China Undergraduate Mathematical Contest in Modeling</a></papertitle> <br>
            <em> China Society for Industrial and Applied Mathematics</em> (CSIAM), 2018<br>
            <span style="color: rgba(255, 0, 0, 0.904);"><strong>National First-Prize Winner</span></strong>, Team: Southwest Jiaotong University (SWJTU)<br>
            Topic: Dynamic Scheduling Strategy for Intelligent RGV Car<br>
            <strong>Zhuoyuan Li</strong>, Zongmou Li, Jinhong He<br>
            Advisor: Lu Wang<br>
            [<a href="./files/SWJTU_MCM/mcm_first.jpg">PDF</a>]
            [<a href="https://www.mcm.edu.cn/">LINK</a>]
          </td>
        </tr>

        <tr>
          <td style="line-height: 1.5;">
            <img src="./images/pic/SWJTU.png" width="200" height="140">
          </td>
          <td>
            <papertitle style="line-height: 1.5;"><a href="http://gjcxcy.bjtu.edu.cn/">
            National University Student Innovation & Entrepreneurship Development Program<br>
            (国家级大学生创新创业训练计划)</a></papertitle> <br>
            <em> Ministry of Education of the People's Republic of China</em>, 2017<br>
            <span style="color: rgba(255, 0, 0, 0.904);"><strong> Obtain Financial Assistance (¥ 15000), Honorable Mention for Conclusive Report</span></strong><br>
            Approved Project Number：201810613033<br>
            Team: Southwest Jiaotong University (SWJTU), Topic: Street Light Management System via Zigbee Net<br>
            Related Paper: <a href="https://www.cqvip.com/QK/97111A/20194/7100299906.html">Zigbee-based Campus Street Light Management System</a><br>
            <strong>Zhuoyuan Li</strong>, Han Tang, Haodong Liu, Hao Zhang, Zongmou Li<br>
            Advisor: Liu Yang, Yan Shi<br>
            [<a href="./files/SWJTU_SRTP/srtp_award.pdf">PDF</a>]
            [<a href="http://gjcxcy.bjtu.edu.cn/">LINK</a>]
          </td>
        </tr>
    </tbody></table>   
    
    <a id="Standard" class="anchor"></a><span class="section">Standardization Activities</a> </span>
    <table border="0" width="95%" class="paper" style="border-collapse:separate; border-spacing:10px;">
      <tbody>
        <tr>
          <td style="line-height: 1.5;">
            <img src="./images/pic/wg1m104003.png" width="200" height="100">
          </td>
          <td>
            <papertitle style="line-height: 1.5;"><a href="https://jpeg.org/jpegxs/">
            Proposal for Intra Pattern Copy of JPEG XS Screen Content Image Coding</a></papertitle><br>
            <em>JPEG XS, ISO/IEC JTC 1/SC 29/WG 1</em>, wg1m104003, 2024<br>
            Yao Li, <strong>Zhuoyuan Li</strong>, Li Li, Dong Liu<br>
            Proposal Organization: University of Science and Technology of China (USTC)<br>
            [<a href="./files/JPEGxs/wg1m104003.pdf">PDF</a>]
          </td>
        </tr>

        <tr>
          <td style="line-height: 1.5;">
            <img src="./images/pic/wg1m104074.png" width="200" height="135">
          </td>
          <td>
            <papertitle style="line-height: 1.5;"><a href="https://jpeg.org/jpegxs/">
            Intra-Picture Decorrelation Tools for JPEG XS Screen Content Coding</a></papertitle><br>
            <em>JPEG XS, ISO/IEC JTC 1/SC 29/WG 1</em>, wg1m104074, 2024<br>
            Yao Li, <strong>Zhuoyuan Li</strong>, Li Li, Dong Liu<br>
            Proposal Organization: University of Science and Technology of China (USTC)<br>
            [<a href="./files/JPEGxs/wg1m104074.pdf">PDF</a>]
          </td>
        </tr>

        <tr>
          <td style="line-height: 1.5;">
            <img src="./images/pic/wg1m104074.png" width="200" height="135">
          </td>
          <td>
            <papertitle style="line-height: 1.5;"><a href="https://jpeg.org/jpegxs/">
            Results of CE 10.2 (Intra Pattern Copy) on JPEG XS by USTC</a></papertitle><br>
            <em>JPEG XS, ISO/IEC JTC 1/SC 29/WG 1</em>, wg1m105026, 2024<br>
            Yao Li, <strong>Zhuoyuan Li</strong>, Li Li, Dong Liu<br>
            Proposal Organization: University of Science and Technology of China (USTC)<br>
            [<a href="./files/JPEGxs/wg1m105026.pdf">PDF</a>]
          </td>
        </tr>

        <tr>
          <td style="line-height: 1.5;">
            <img src="./images/pic/M8526.png" width="200" height="100">
          </td>
          <td>
            <papertitle style="line-height: 1.5;"><a href="https://www.avs.org.cn/">
            一种用于稳定EEM训练的验证集USTC-TD</a></papertitle><br>
            <em>AVS 90#, 威海</em>, M8526, 2024<br>
            唐传波，卞逸凡，盛锡华，<strong>李卓元</strong>，李礼，刘东<br>
            Proposal Organization: University of Science and Technology of China (USTC)<br>
            [<a href="./files/AVS-EEM/M8526.pdf">PDF</a>]
          </td>
        </tr>
        
        <tr>
          <td style="line-height: 1.5;">
            <img src="./images/pic/M8987.png" width="200" height="160">
          </td>
          <td>
            <papertitle style="line-height: 1.5;"><a href="https://www.avs.org.cn/">
            一种用于EEM的测试集USTC-TD 及其测试基准</a></papertitle><br>
            <em>AVS 93#, 沈阳</em>, M8987, 2024<br>
            <strong>李卓元</strong>, 廖峻骐, 唐传波, 张昊田, 卞逸凡, 李瑶, 盛锡华,  梁雄壮, 李宇琪,<br> 
            冯新民, 左之睿, 李佳林, 汪家振, 蒋易恒, 向辉, 李礼, 刘东, 吴枫<br>
            Proposal Organization: University of Science and Technology of China (USTC)<br>
            [<a href="./files/AVS-EEM/M8987.pdf">PDF</a>]
          </td>
        </tr>

        <tr>
          <td style="line-height: 1.5;">
            <img src="./images/pic/M8984.png" width="200" height="110">
          </td>
          <td>
            <papertitle style="line-height: 1.5;"><a href="https://www.avs.org.cn/">
            EEM I 帧模型改进</a></papertitle><br>
            <em>AVS 93#, 沈阳</em>, M8984, 2024<br>
            李宇琪, 张昊田, 李瑶, <strong>李卓元</strong>, 李礼, 刘东<br>
            Proposal Organization: University of Science and Technology of China (USTC)<br>
            [<a href="./files/AVS-EEM/M8984.pdf">PDF</a>]
          </td>
        </tr>

      </tbody>
    </table>

   <a id="projects" class="anchor"></a><span class="section">Projects</a> </span>
   <table border="0" width="95%" class="paper" style="border-collapse:separate; border-spacing:10px;">
     <tbody>

     <tr>
      <td>
      &nbsp; &nbsp; &nbsp; &nbsp;
      </td>
       <td>
         <img src="./images/pic/ustc-td.png" width="380" height="150">
       </td>
       <td>
        &nbsp; &nbsp; &nbsp; &nbsp;
       </td>
       <td>
         <papertitle><a href="https://esakak.github.io/USTC-TD/">
          USTC-TD: A Test Dataset and Benchmark for Image and Video Coding in 2020s</a></papertitle> <br>
          <strong>Zhuoyuan Li</strong>, Junqi Liao (Co-first), Chuanbo Tang, Haotian Zhang, Yuqi Li, Yifan Bian, Xihua Sheng, Xinmin Feng, Yao Li, Changsheng Gao, Li Li, Dong Liu*, and Feng Wu* <br>
          [<a href="./files/USTC-TD/USTC-TD.pdf">PDF</a>] 
          [<a href="./files/USTC-TD/sup.pdf">Supplementary</a>]
          [<a href="https://arxiv.org/abs/2409.08481">arXiv</a>]
          [<a href="https://esakak.github.io/USTC-TD/">Project Page</a>]
          [<a href="https://github.com/EsakaK/USTC-TD">Data</a>]
          [<a href="https://github.com/EsakaK/USTC-TD/tree/main/code">Code</a>]
       </td>
     </tr>
   </tbody></table>

  <a id="services"></a><span class="section">Academic Services</span>
  <p></p>
  <strong>Reviewer of Journals:</strong>
  <ul>
    <li>
      <p style="line-height: 170%; margin-left: 15px; margin-top: 3pt; margin-bottom: 0pt;"><b>
        <font color="#000000" face='Lato' size="2"><b>
          IEEE Transactions on Image Processing  (TIP) </font></b></p>
    </li>

    <li>
      <p style="line-height: 170%; margin-left: 15px; margin-top: 3pt; margin-bottom: 0pt;"><b>
        <font color="#000000" face='Lato' size="2"><b>
          IEEE Transactions on Multimdeia (TMM) </font></b></p>
    </li>

    <li>
      <p style="line-height: 170%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;"><b>
        <font color="#000000" face='Lato' size="2"><b>
          IEEE Transactions on Circuits and Systems for Video Technology (TCSVT) </font></b></p>
    </li>

    <li>
      <p style="line-height: 170%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;"><b>
        <font color="#000000" face='Lato' size="2"><b>
          IEEE Transactions on Broadcasting (TBC) </font></b></p>
    </li>

    <li>
      <p style="line-height: 170%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;"><b>
        <font color="#000000" face='Lato' size="2"><b>
          ACM Transactions on Multimedia Computing, Communications, and Applications (TOMM) </font></b></p>
    </li>
    
    <li>
      <p style="line-height: 170%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;"><b>
        <font color="#000000" face='Lato' size="2"><b>
          IEEE Internet Things of Journal (IOT) </font></b></p>
    </li>

    <li>
      <p style="line-height: 170%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;"><b>
        <font color="#000000" face='Lato' size="2"><b>
          IEEE Open Journal of Signal Processing (OJSP) </font></b></p>
    </li>

    <li>
      <p style="line-height: 170%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;"><b>
        <font color="#000000" face='Lato' size="2"><b>
          International Journal of Image and Graphics (IJIG) </font></b></p>
    </li>

    <li>
      <p style="line-height: 170%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;"><b>
        <font color="#000000" face='Lato' size="2"><b>
          Artificial Intelligence Review (AIR) </font></b></p>
    </li>
  </ul>
  <p></p>
  <strong>Reviewer of Conferences:</strong>
  <ul>  
    <li>
      <p style="line-height: 150%; margin-left: 15px; margin-top: 4pt; margin-bottom: 0pt;"><b>
        <font color="#000000" face='Lato' size="2"><b>
          ACM International Conference on Multimedia (ACM MM 2022)</font></b></p>
    </li>

    <li>
      <p style="line-height: 150%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;"><b>
        <font color="#000000" face='Lato' size="2"><b>
          ACM International Conference on Multimedia (ACM MM 2023)</font></b></p>
    </li>

    <li>
      <p style="line-height: 150%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;"><b>
        <font color="#000000" face='Lato' size="2"><b>
          ACM International Conference on Multimedia (ACM MM 2024)</font></b></p>
    </li>

    <li>
      <p style="line-height: 150%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;"><b>
        <font color="#000000" face='Lato' size="2"><b>
          ACM International Conference on Multimedia (ACM MM 2025)</font></b></p>
    </li>

    <li>
      <p style="line-height: 150%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;"><b>
        <font color="#000000" face='Lato' size="2"><b>
          ACM International Conference on Multimedia (ACM MM 2025), Dataset Track</font></b></p>
    </li>

    <li>
      <p style="line-height: 150%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;"><b>
        <font color="#000000" face='Lato' size="2"><b>
          ACM International Conference on Multimedia (ACM MM Asia 2025)</font></b></p>
    </li>

    <li>
      <p style="line-height: 150%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;"><b>
        <font color="#000000" face='Lato' size="2"><b>
          Neural Information Processing Systems (NeurIPS 2024)</font></b></p>
    </li>

    <li>
      <p style="line-height: 150%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;"><b>
        <font color="#000000" face='Lato' size="2"><b>
          Neural Information Processing Systems (NeurIPS 2025)</font></b></p>
    </li>

    <li>
      <p style="line-height: 150%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;"><b>
        <font color="#000000" face='Lato' size="2"><b>
          International Conference on Computer Vision and Pattern Recognition  (CVPR 2026)</font></b></p>
    </li>

    <li>
      <p style="line-height: 150%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;"><b>
        <font color="#000000" face='Lato' size="2"><b>
          Proceedings of the AAAI Conference on Artificial Intelligence (AAAI 2026)</font></b></p>
    </li>

    <li>
      <p style="line-height: 150%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;"><b>
        <font color="#000000" face='Lato' size="2"><b>
          International Conference on Learning Representations (ICLR 2025)</font></b></p>
    </li>

    <li>
      <p style="line-height: 150%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;"><b>
        <font color="#000000" face='Lato' size="2"><b>
          International Conference on Learning Representations (ICLR 2026)</font></b></p>
    </li>

    <li>
      <p style="line-height: 150%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;"><b>
        <font color="#000000" face='Lato' size="2"><b>
          International Conference on Machine Learning (ICML 2025)</font></b></p>
    </li>

    <li>
      <p style="line-height: 150%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;"><b>
        <font color="#000000" face='Lato' size="2"><b>
          International Joint Conference on Artificial Intelligence (IJCAI 2025)</font></b></p>
    </li>  
    
    <li>
      <p style="line-height: 150%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;"><b>
        <font color="#000000" face='Lato' size="2"><b>
          European Conference on Artificial Intelligence (ECAI 2025)</font></b></p>
    </li>
       
    <li>
      <p style="line-height: 150%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;"><b>
        <font color="#000000" face='Lato' size="2"><b>
          IEEE International Conference on Multimedia & Expo (ICME 2025)</font></b></p>
    </li>

    <li>
      <p style="line-height: 150%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;"><b>
        <font color="#000000" face='Lato' size="2"><b>
          IEEE International Conference on Multimedia & Expo (ICME 2026)</font></b></p>
    </li>

    <li>
      <p style="line-height: 150%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;"><b>
        <font color="#000000" face='Lato' size="2"><b>
          International Conference on Pattern Recognition (ICPR 2024)</font></b></p>
    </li>

    <li>
      <p style="line-height: 150%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;"><b>
        <font color="#000000" face='Lato' size="2"><b>
          International Joint Conference on Neural Networks (IJCNN 2025)</font></b></p>
    </li>

    <li>
      <p style="line-height: 150%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;"><b>
        <font color="#000000" face='Lato' size="2"><b>
          IEEE International Workshop on Multimedia Signal Processing (MMSP 2024)</font></b></p>
    </li>

    <li>
      <p style="line-height: 150%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;"><b>
        <font color="#000000" face='Lato' size="2"><b>
          IEEE International Workshop on Multimedia Signal Processing (MMSP 2025)</font></b></p>
    </li>

    <li>
      <p style="line-height: 150%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;"><b>
        <font color="#000000" face='Lato' size="2"><b>
          IEEE International Conference on Visual Communication and Image Processing Conference (VCIP 2023)</font></b></p>
    </li>

    <li>
      <p style="line-height: 150%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;"><b>
        <font color="#000000" face='Lato' size="2"><b>
          IEEE International Conference on Visual Communication and Image Processing Conference (VCIP 2024)</font></b></p>
    </li>

    <li>
      <p style="line-height: 150%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;"><b>
        <font color="#000000" face='Lato' size="2"><b>
          IEEE International Conference on Visual Communication and Image Processing Conference (VCIP 2025)</font></b></p>
    </li>

    <li>
      <p style="line-height: 150%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;"><b>
        <font color="#000000" face='Lato' size="2"><b>
          International Conference on Wireless Communications and Signal Processing (WCSP 2024)</font></b></p>
    </li>

    <li>
      <p style="line-height: 150%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;"><b>
        <font color="#000000" face='Lato' size="2"><b>
          Data Compression Conference  (DCC 2025)</font></b></p>
    </li>

    <li>
      <p style="line-height: 150%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;"><b>
        <font color="#000000" face='Lato' size="2"><b>
          Data Compression Conference  (DCC 2026)</font></b></p>
    </li>

    <li>
      <p style="line-height: 150%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;"><b>
        <font color="#000000" face='Lato' size="2"><b>
          International Conference on Acoustics, Speech and Signal Processing  (ICASSP 2025)</font></b></p>
    </li>

    <li>
      <p style="line-height: 150%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;"><b>
        <font color="#000000" face='Lato' size="2"><b>
          International Conference on Acoustics, Speech and Signal Processing  (ICASSP 2026)</font></b></p>
    </li>


    <li>
      <p style="line-height: 150%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;"><b>
        <font color="#000000" face='Lato' size="2"><b>
          International Conference on Artificial Intelligence and Statistics (AISTATS 2025)</font></b></p>
    </li>

    <li>
      <p style="line-height: 150%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;"><b>
        <font color="#000000" face='Lato' size="2"><b>
          International Conference on Artificial Intelligence and Statistics (AISTATS 2026)</font></b></p>
    </li>
  </ul>

  <a id="Talks" class="anchor"></a><span class="section">Talks</a> </span>
  <table border="0" width="95%" class="paper" style="border-collapse:separate; border-spacing:1px;">
      <tbody>
        <tr>
          <td style="line-height: 1;">
            <img src="./images/pic/ivc.png" width="200" height="180">
          </td>
          <td>
            <papertitle style="line-height: 1.2;"><a href="https://ustc-ivclab.github.io/">
            An Introduction for Panoramic Video Coding and Transcoding</a></papertitle><br>
            <em> USTC-iVC Paper Reading</em>, 2023<br>
            Zhuoyuan Li, Yao Li<br>
            [<a href="./files/Talks/panoramic.pdf">PDF</a>]
          </td>

          <td style="line-height: 1;">
            <img src="./images/pic/ivc.png" width="200" height="180">
          </td>
          <td>
            <papertitle style="line-height: 1.2;"><a href="https://ustc-ivclab.github.io/">
            Overview of Inter Prediction in Recent Years</a></papertitle> <br>
            <em> USTC-iVC Paper Reading</em>, 2022<br>
            Zhuoyuan Li, Yao Li<br>
            [<a href="./files/Talks/inter.pdf">PDF</a>]
          </td>
        </tr>
    </tbody>
  </table>

  <span class="section">Participant Conference</a></span>
  <table border="0" width="95%" class="paper" style="border-collapse:separate; border-spacing:10px;">
  <ul>
    <li>
      <p style="line-height: 150%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;"><b>
      <font color="#000000" face='Lato' size="2"><b>
        IEEE International Conference on Image Processing (ICIP 2025), Anchorage, United States</font></b></p>
    </li>
    <li>
      <p style="line-height: 150%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;"><b>
      <font color="#000000" face='Lato' size="2"><b>
        IEEE International Conference on Image Processing (ICIP 2024), Abu Dhabi, United Arab Emirates</font></b></p>
    </li>
    <li>
      <p style="line-height: 150%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;"><b>
        <font color="#000000" face='Lato' size="2"><b>
        IEEE International Conference on Image Processing (ICIP 2023), Kuala Lumpur, Malaysia</font></b></p>
    </li>
    <li>
      <p style="line-height: 150%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;"><b>
      <font color="#000000" face='Lato' size="2"><b>
        IEEE International Conference on Visual Communications and Image Processing (VCIP 2025), Klagenfurt, Austria</font></b></p>
    </li>
    <li>
      <p style="line-height: 150%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;"><b>
      <font color="#000000" face='Lato' size="2"><b>
        IEEE International Conference on Visual Communications and Image Processing (VCIP 2024), Tokyo, Japan</font></b></p>
    </li>
    <li>
      <p style="line-height: 150%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;"><b>
      <font color="#000000" face='Lato' size="2"><b>
      IEEE International Conference on Visual Communications and Image Processing (VCIP 2023), Jeju, Korea</font></b></p>
    </li>
    <li>
      <p style="line-height: 150%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;"><b>
      <font color="#000000" face='Lato' size="2"><b>
      China Multimedia (ChinaMM 2025), Weihai, China</font></b></p>
    </li>
    <li>
      <p style="line-height: 150%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;"><b>
      <font color="#000000" face='Lato' size="2"><b>
      China Multimedia (ChinaMM 2024), Yinchuan, China</font></b></p>
    </li>
    <li>
      <p style="line-height: 150%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;"><b>
      <font color="#000000" face='Lato' size="2"><b>
      Vision and Learning Seminar (VALSE 2025), Zhuhai, China</font></b></p>
    </li>
    <li>
      <p style="line-height: 150%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;"><b>
      <font color="#000000" face='Lato' size="2"><b>
      Vision and Learning Seminar (VALSE 2024), Chongqing, China</font></b></p>
    </li>
    <li>
      <p style="line-height: 150%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;"><b>
      <font color="#000000" face='Lato' size="2"><b>
      Chinese Congress on Image and Graphics (CCIG 2025), Changsha, China</font></b></p>
    </li>
    <li>
      <p style="line-height: 150%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;"><b>
      <font color="#000000" face='Lato' size="2"><b>
      Chinese Congress on Image and Graphics (CCIG 2024), Xi'an, China</font></b></p>
    </li>
    <li>
      <p style="line-height: 150%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;"><b>
      <font color="#000000" face='Lato' size="2"><b>
      China Symposium on Machine Learning and Applications (MLA 2024), Hefei, China</font></b></p>
    </li>
    <li>
      <p style="line-height: 150%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;"><b>
      <font color="#000000" face='Lato' size="2"><b>
        CCF Young Computer Scientists & Engineers Forum (CCF YOCSEF 2024), Hefei, China</font></b></p>
    </li>
    <li>
      <p style="line-height: 150%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;"><b>
      <font color="#000000" face='Lato' size="2"><b>
        AVS-Audio Video Coding Standard Workgroup of China 87, Chengdu, China</font></b></p>
    </li>
    <li>
      <p style="line-height: 150%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;"><b>
      <font color="#000000" face='Lato' size="2"><b>
        AVS-Audio Video Coding Standard Workgroup of China 93, Shenyang, China</font></b></p>
    </li>
    <li>
      <p style="line-height: 150%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;"><b>
      <font color="#000000" face='Lato' size="2"><b>
        中国图象图形学学会青年科学家会议 2025, Qingdao, China</font></b></p>
    </li>
    <li>
      <p style="line-height: 150%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;"><b>
      <font color="#000000" face='Lato' size="2"><b>
        中国图象图形学学会青年科学家会议 2024, Hangzhou, China</font></b></p>
    </li>
    <li>
      <p style="line-height: 150%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;"><b>
      <font color="#000000" face='Lato' size="2"><b>
        空间信息技术及产业发展大会 2024, Hefei, China</font></b></p>
    </li>
    <li>
      <p style="line-height: 150%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;"><b>
      <font color="#000000" face='Lato' size="2"><b>
        人工智能前沿论坛 2024, Hefei, China</font></b></p>
    </li>
  </ul>

  <p><font color="#000000" face='Lato' size="2">&copy 2024.11.14 Zhuoyuan Li. Thanks to <a href="https://ruizhao26.github.io/">Dr. Rui Zhao, </a><a href="http://people.csail.mit.edu/celiu">Dr. Ce Liu</a> and 
  <a href="https://deqings.github.io/index.html">Dr. Deqing Sun</a> for the template.</p>

</body></html>
